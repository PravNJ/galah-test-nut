{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import astropy.io.fits as pyfits\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "#this is for Sven Buder's fits file reader function which reads fits into a Python dict of numpy arrays"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from spectres import spectres\n",
    "#these are for running spectres which allows us to resample spectra and their errors with very little effort "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#sobject_ids = [161217002601184,170418003701205] \n",
    "#sobject_ids = [170418003701205] \n",
    "import pandas as pd \n",
    "\n",
    "df_full= pd.read_csv(\"/disks/nut/home/46670564/praveen/code/galah-test-nut/GALAH_all_sobject_ids.csv\") #full GALAH catalog\n",
    "\n",
    "df_missing = pd.read_csv(\"/disks/nut/home/46670564/praveen/code/galah-test-nut/GALAH_DR3_list_missing_normalized_spectra_v2.csv\", header=None) #GALAH objects with missing normalised spectra \n",
    "df_full.drop(['Unnamed: 0'], axis=1)\n",
    "df_missing.columns = ['sobject_id']\n",
    "\n",
    "df_temp = pd.merge(df_full, df_missing, how='outer', indicator=True)\n",
    "df_final_sobject_ids_temp = df_temp.loc[df_temp['_merge'] == \"left_only\"].drop([\"Unnamed: 0\",\"_merge\"], axis=1)\n",
    "\n",
    "np.random.seed(1) #set seed here \n",
    "sobject_ids = df_final_sobject_ids_temp.loc[np.random.choice(df_final_sobject_ids_temp.index, size=5000)][\"sobject_id\"].to_numpy().tolist()\n",
    "\n",
    "#input the object IDs, change this later to handle a list of 30K object IDs\n",
    "#these object IDs will drive the read_spectra method\n",
    "#calling read_spectra using object IDs in a loop will be useful to iterate through all the objects and generate dict() objects for their spectra "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "GRID_SIZE = 0.06\n",
    "LOWER_LAMBDA = 6472.5\n",
    "UPPER_LAMBDA = 6740\n",
    "\n",
    "#the grid size was determined by looking at camera 3 for a few fits files and checking the step between lambda values that are general enough for all fits files \n",
    "#lower and upper limites are from Sven Buder's example for camera 3\n",
    "#this constants will have to be adjusted depending on the element being studied and the minimum resolution of the wave grid (lambda values i.e. lambda[i+1] - lambda[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "regrid = np.arange(LOWER_LAMBDA, UPPER_LAMBDA, GRID_SIZE) \n",
    "\n",
    "#this is the grid onto which spectres will resampple "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def read_spectra(sobject_id):\n",
    "    fits_files = [[],[],[],[]]\n",
    "    for each_ccd in [1,2,3,4]:\n",
    "        fits_files[each_ccd-1] = glob.glob('/data/praveen/galah-total/galah/dr3/spectra/hermes/'+str(sobject_id)+str(each_ccd)+'.fits') #this is reading fits files from file and not downloading directly \n",
    "\n",
    "    spectrum = dict()\n",
    "    for each_ccd in [1,2,3,4]: #GALAH uses indexing from 1 - 4\n",
    "        if fits_files[each_ccd-1]!=[]: #just using zero indexing here \n",
    "            fits = pyfits.open(fits_files[each_ccd-1][0]) \n",
    "            \n",
    "            # Extension 0: Reduced spectrum\n",
    "            # Extension 1: Relative error spectrum\n",
    "            # Extension 4: Normalised spectrum, NB: cut for CCD4\n",
    "\n",
    "            # Extract wavelength grid for the reduced spectrum\n",
    "            start_wavelength = fits[0].header[\"CRVAL1\"]\n",
    "            dispersion       = fits[0].header[\"CDELT1\"]\n",
    "            nr_pixels        = fits[0].header[\"NAXIS1\"]\n",
    "            reference_pixel  = fits[0].header[\"CRPIX1\"]\n",
    "\n",
    "            if reference_pixel == 0:\n",
    "                reference_pixel = 1\n",
    "            spectrum['wave_red_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength) #this is the reduced spectrum \n",
    "\n",
    "            # Extract wavelength grid for the normalised spectrum\n",
    "            start_wavelength = fits[4].header[\"CRVAL1\"]\n",
    "            dispersion       = fits[4].header[\"CDELT1\"]\n",
    "            nr_pixels        = fits[4].header[\"NAXIS1\"]\n",
    "            reference_pixel  = fits[4].header[\"CRPIX1\"]\n",
    "\n",
    "            if reference_pixel == 0:\n",
    "                reference_pixel=1\n",
    "            spectrum['wave_norm_'+str(each_ccd)] = ((np.arange(0,nr_pixels)--reference_pixel+1)*dispersion+start_wavelength) #this is the normalised spectrum \n",
    "\n",
    "            spectrum['sob_red_'+str(each_ccd)]  = np.array(fits[0].data)\n",
    "            spectrum['uob_red_'+str(each_ccd)]  = np.array(fits[0].data * fits[1].data)\n",
    "\n",
    "            spectrum['sob_norm_'+str(each_ccd)] = np.array(fits[4].data)\n",
    "            if each_ccd != 4:\n",
    "                spectrum['uob_norm_'+str(each_ccd)] = np.array(fits[4].data * fits[1].data)\n",
    "            else:\n",
    "                # for normalised error of CCD4, only used appropriate parts of error spectrum\n",
    "                spectrum['uob_norm_4'] = np.array(fits[4].data * (fits[1].data)[-len(spectrum['sob_norm_4']):])\n",
    "\n",
    "            fits.close()\n",
    "        else:\n",
    "            spectrum['wave_red_'+str(each_ccd)] = []\n",
    "            spectrum['wave_norm_'+str(each_ccd)] = []\n",
    "            spectrum['sob_red_'+str(each_ccd)] = []\n",
    "            spectrum['sob_norm_'+str(each_ccd)] = []\n",
    "            spectrum['uob_red_'+str(each_ccd)] = []\n",
    "            spectrum['uob_norm_'+str(each_ccd)] = []\n",
    "    \n",
    "    spectrum['wave_red'] = np.concatenate(([spectrum['wave_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['wave_norm'] = np.concatenate(([spectrum['wave_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['sob_red'] = np.concatenate(([spectrum['sob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['sob_norm'] = np.concatenate(([spectrum['sob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['uob_red'] = np.concatenate(([spectrum['uob_red_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "    spectrum['uob_norm'] = np.concatenate(([spectrum['uob_norm_'+str(each_ccd)] for each_ccd in [1,2,3,4]]))\n",
    "\n",
    "    return spectrum \n",
    "    \n",
    "    #returns a 30 \"row\" dict of numpy array per row 'wave_red_x' is the key for the key value pair\n",
    "    #camera 3 will be the more useful canmera for Li spectra "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def resample_spectra(spectrum, camera, verbose):\n",
    "\n",
    "    spec_resample, spec_errs_resample = spectres(regrid,  spectrum['wave_norm_'+str(camera)], spectrum['sob_norm_'+str(camera)], spec_errs= spectrum['uob_norm_'+str(camera)],verbose=verbose) \n",
    "\n",
    "    return spec_resample, spec_errs_resample\n",
    "\n",
    "#for Li pick camera 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#open an empty dict to store the results \n",
    "resampled_spectra_collection = {}\n",
    "resampled_spectra_collection['spec_resample'] = []\n",
    "\n",
    "resampled_error_collection = {}\n",
    "resampled_error_collection['error_resample'] = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "for sobject_id in sobject_ids:\n",
    "    #this is the normalised resampled spectra \n",
    "    temp_spectrum = resample_spectra(read_spectra(sobject_id), 3, False)\n",
    "    temp_spectrum[0][np.isnan(temp_spectrum[0])] = 1 #padding \n",
    "    resampled_spectra_collection['spec_resample'].append(temp_spectrum[0])\n",
    "\n",
    "    #these are the error spectra\n",
    "    #calculate mean error for padding \n",
    "\n",
    "    non_na_values = temp_spectrum[1][~np.isnan(temp_spectrum[1])]\n",
    "    mean_error = np.mean(non_na_values)\n",
    "\n",
    "    temp_spectrum[1][np.isnan(temp_spectrum[1])] = mean_error\n",
    "    resampled_error_collection['error_resample'].append(temp_spectrum[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "import h5py\n",
    "\n",
    "#save the resampled spectra to be used as inputs to the training set\n",
    "hf_spec = h5py.File(\"/data/praveen/results/resampled_test_spectra1.h5\", \"w\")\n",
    "hf_spec.create_dataset('spectra', data=resampled_spectra_collection['spec_resample'])\n",
    "hf_spec.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#save the wavelength grid \n",
    "hf_grid = h5py.File(\"/data/praveen/results/wl_grid.h5\", \"w\")\n",
    "hf_grid.create_dataset('wl_grid', data=regrid)\n",
    "hf_grid.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#save the error spectra\n",
    "hf_error = h5py.File(\"/data/praveen/results/resampled_test_errors1.h5\", \"w\")\n",
    "hf_error.create_dataset('errors', data=resampled_error_collection['error_resample'])\n",
    "hf_error.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('galah_38': conda)"
  },
  "interpreter": {
   "hash": "990dc4f98e772390967ebb58feb6d8ba345f9894e89a1f74c7ac4577afaa2020"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}