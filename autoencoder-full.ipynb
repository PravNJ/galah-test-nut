{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dr3_all = pd.read_csv(\"/data/praveen/results/dr3_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "unproblem_ids = pd.read_csv(\"/data/praveen/results/unproblem_ids.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sobject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160327005601122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160327005601123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>160327005601124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>160327005601125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160327005601126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sobject_id\n",
       "0  160327005601122\n",
       "1  160327005601123\n",
       "2  160327005601124\n",
       "3  160327005601125\n",
       "4  160327005601126"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unproblem_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sobject_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4449</th>\n",
       "      <th>4450</th>\n",
       "      <th>4451</th>\n",
       "      <th>4452</th>\n",
       "      <th>4453</th>\n",
       "      <th>4454</th>\n",
       "      <th>4455</th>\n",
       "      <th>4456</th>\n",
       "      <th>4457</th>\n",
       "      <th>4458</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131116000501002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131116000501004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131116000501005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131116000501006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131116000501007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sobject_id    0    1    2    3    4    5    6    7    8  ...  4449  \\\n",
       "0  131116000501002  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "1  131116000501004  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "2  131116000501005  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "3  131116000501006  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "4  131116000501007  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "\n",
       "   4450  4451  4452  4453  4454  4455  4456  4457  4458  \n",
       "0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "1   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "2   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "3   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "4   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "\n",
       "[5 rows x 4460 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dr3_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.merge(df_dr3_all,unproblem_ids, how='outer', indicator=True, on=\"sobject_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both          356299\n",
       "left_only     232045\n",
       "right_only         0\n",
       "Name: _merge, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp[\"_merge\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_ids = df_temp.loc[df_temp[\"_merge\"]==\"both\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sobject_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4450</th>\n",
       "      <th>4451</th>\n",
       "      <th>4452</th>\n",
       "      <th>4453</th>\n",
       "      <th>4454</th>\n",
       "      <th>4455</th>\n",
       "      <th>4456</th>\n",
       "      <th>4457</th>\n",
       "      <th>4458</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131116000501002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131116000501005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131116000501006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131116000501007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>131116000501012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4461 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sobject_id    0    1    2    3    4    5    6    7    8  ...  4450  \\\n",
       "0  131116000501002  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "2  131116000501005  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "3  131116000501006  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "4  131116000501007  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "7  131116000501012  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "\n",
       "   4451  4452  4453  4454  4455  4456  4457  4458  _merge  \n",
       "0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0    both  \n",
       "2   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0    both  \n",
       "3   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0    both  \n",
       "4   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0    both  \n",
       "7   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0    both  \n",
       "\n",
       "[5 rows x 4461 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19871/279852445.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  good_ids_data_only = good_ids.drop([\"sobject_id\",\"_merge\"],1)\n"
     ]
    }
   ],
   "source": [
    "good_ids_data_only = good_ids.drop([\"sobject_id\",\"_merge\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4449</th>\n",
       "      <th>4450</th>\n",
       "      <th>4451</th>\n",
       "      <th>4452</th>\n",
       "      <th>4453</th>\n",
       "      <th>4454</th>\n",
       "      <th>4455</th>\n",
       "      <th>4456</th>\n",
       "      <th>4457</th>\n",
       "      <th>4458</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  4449  4450  4451  \\\n",
       "0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "2  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "3  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "4  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "7  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   1.0   1.0   \n",
       "\n",
       "   4452  4453  4454  4455  4456  4457  4458  \n",
       "0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "2   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "3   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "4   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "7   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "\n",
       "[5 rows x 4459 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_ids_data_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_only_inverted = 1 - good_ids_data_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import backend as K\n",
    "#from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = None  # PReLU if set to None\n",
    "dropout_rate = 0  # from 0 to 1\n",
    "n_l_e = 5\n",
    "n_epoch = 350\n",
    "decoded_layer_name = 'encoded'\n",
    "n_wvl = 4459\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# compute number of nodes in every connected layer\n",
    "n_l_1 = int(n_wvl * 0.75)\n",
    "n_l_2 = int(n_wvl * 0.50)\n",
    "n_l_3 = 0  # int(n_wvl * 0.40)\n",
    "n_l_4 = 0  # int(n_wvl * 0.20)\n",
    "n_l_5 = int(n_wvl * 0.25)\n",
    "n_l_6 = int(n_wvl * 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " E_1 (Dense)                 (None, 3344)              14914240  \n",
      "                                                                 \n",
      " PR_1 (PReLU)                (None, 3344)              3344      \n",
      "                                                                 \n",
      " E_2 (Dense)                 (None, 2229)              7456005   \n",
      "                                                                 \n",
      " PR_2 (PReLU)                (None, 2229)              2229      \n",
      "                                                                 \n",
      " E_5 (Dense)                 (None, 1114)              2484220   \n",
      "                                                                 \n",
      " PR_5 (PReLU)                (None, 1114)              1114      \n",
      "                                                                 \n",
      " E_6 (Dense)                 (None, 445)               496175    \n",
      "                                                                 \n",
      " PR_6 (PReLU)                (None, 445)               445       \n",
      "                                                                 \n",
      " encoded (Dense)             (None, 5)                 2230      \n",
      "                                                                 \n",
      " PR_7 (PReLU)                (None, 5)                 5         \n",
      "                                                                 \n",
      " D_1 (Dense)                 (None, 445)               2670      \n",
      "                                                                 \n",
      " PR_8 (PReLU)                (None, 445)               445       \n",
      "                                                                 \n",
      " D_2 (Dense)                 (None, 1114)              496844    \n",
      "                                                                 \n",
      " PR_9 (PReLU)                (None, 1114)              1114      \n",
      "                                                                 \n",
      " D_5 (Dense)                 (None, 2229)              2485335   \n",
      "                                                                 \n",
      " PR_12 (PReLU)               (None, 2229)              2229      \n",
      "                                                                 \n",
      " D_6 (Dense)                 (None, 3344)              7457120   \n",
      "                                                                 \n",
      " PR_13 (PReLU)               (None, 3344)              3344      \n",
      "                                                                 \n",
      " recreated (Dense)           (None, 4459)              14915355  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,724,463\n",
      "Trainable params: 50,724,463\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Sequential()\n",
    "\n",
    "if n_l_1 > 0:\n",
    "    autoencoder.add(Dense(n_l_1, input_shape=(n_wvl,), activation=activation, name='E_1'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_1'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_1'))\n",
    "\n",
    "if n_l_2 > 0:\n",
    "    autoencoder.add(Dense(n_l_2, activation=activation, name='E_2'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_2'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_2'))\n",
    "\n",
    "if n_l_3 > 0:\n",
    "    autoencoder.add(Dense(n_l_3, activation=activation, name='E_3'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_3'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_3'))\n",
    "\n",
    "if n_l_4 > 0:\n",
    "    autoencoder.add(Dense(n_l_4, activation=activation, name='E_4'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_4'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_4'))\n",
    "\n",
    "if n_l_5 > 0:\n",
    "    autoencoder.add(Dense(n_l_5, activation=activation, name='E_5'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_5'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_5'))\n",
    "\n",
    "if n_l_6 > 0:\n",
    "    autoencoder.add(Dense(n_l_6, activation=activation, name='E_6'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_6'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_6'))\n",
    "\n",
    "autoencoder.add(Dense(n_l_e, activation=activation, name=decoded_layer_name))\n",
    "if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_7'))\n",
    "\n",
    "if n_l_6 > 0:\n",
    "    autoencoder.add(Dense(n_l_6, activation=activation, name='D_1'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_8'))\n",
    "    if activation is None:\n",
    "            autoencoder.add(PReLU(name='PR_8'))\n",
    "\n",
    "if n_l_5 > 0:\n",
    "    autoencoder.add(Dense(n_l_5, activation=activation, name='D_2'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_9'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_9'))\n",
    "\n",
    "if n_l_4 > 0:\n",
    "    autoencoder.add(Dense(n_l_4, activation=activation, name='D_3'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_10'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_10'))\n",
    "\n",
    "if n_l_3 > 0:\n",
    "    autoencoder.add(Dense(n_l_3, activation=activation, name='D_4'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_11'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_11'))\n",
    "\n",
    "if n_l_2 > 0:\n",
    "    autoencoder.add(Dense(n_l_2, activation=activation, name='D_5'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_12'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_12'))\n",
    "\n",
    "if n_l_1 > 0:\n",
    "    autoencoder.add(Dense(n_l_1, activation=activation, name='D_6'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_13'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_13'))\n",
    "\n",
    "autoencoder.add(Dense(n_wvl, activation='linear', name='recreated'))\n",
    "autoencoder.summary()\n",
    "\n",
    "# Visualize network architecture and save the visualization as a file\n",
    "#plot_model(autoencoder, show_layer_names=True, show_shapes=True, to_file='ann_network_structure_a.pdf')\n",
    "#plot_model(autoencoder, show_layer_names=True, show_shapes=True, to_file='ann_network_structure_a.png', dpi=300)\n",
    "\n",
    "# model file handling\n",
    "out_model_file = 'model_weights.h5'\n",
    "\n",
    "if os.path.isfile(out_model_file):\n",
    "    autoencoder.load_weights(out_model_file, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=optimizer, loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('/data/praveen/autoencoder-run-3/'+'ann_model_run_{epoch:03d}-{loss:.4f}-{val_loss:.4f}.h5',\n",
    "                                     monitor='val_loss', verbose=0, save_best_only=False,\n",
    "                                     save_weights_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 11:20:01.319558: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 11438904568 exceeds 10% of free system memory.\n",
      "2022-05-11 11:22:03.658147: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 11438904568 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "9/9 - 210s - loss: 0.0343 - val_loss: 0.0267 - 210s/epoch - 23s/step\n",
      "Epoch 2/350\n",
      "9/9 - 169s - loss: 0.0239 - val_loss: 0.0200 - 169s/epoch - 19s/step\n",
      "Epoch 3/350\n",
      "9/9 - 156s - loss: 0.0187 - val_loss: 0.0187 - 156s/epoch - 17s/step\n",
      "Epoch 4/350\n",
      "9/9 - 168s - loss: 0.0165 - val_loss: 0.0148 - 168s/epoch - 19s/step\n",
      "Epoch 5/350\n",
      "9/9 - 176s - loss: 0.0144 - val_loss: 0.0136 - 176s/epoch - 20s/step\n",
      "Epoch 6/350\n",
      "9/9 - 179s - loss: 0.0136 - val_loss: 0.0132 - 179s/epoch - 20s/step\n",
      "Epoch 7/350\n",
      "9/9 - 179s - loss: 0.0132 - val_loss: 0.0129 - 179s/epoch - 20s/step\n",
      "Epoch 8/350\n",
      "9/9 - 179s - loss: 0.0132 - val_loss: 0.0130 - 179s/epoch - 20s/step\n",
      "Epoch 9/350\n",
      "9/9 - 167s - loss: 0.0128 - val_loss: 0.0128 - 167s/epoch - 19s/step\n",
      "Epoch 10/350\n",
      "9/9 - 180s - loss: 0.0127 - val_loss: 0.0126 - 180s/epoch - 20s/step\n",
      "Epoch 11/350\n",
      "9/9 - 182s - loss: 0.0126 - val_loss: 0.0126 - 182s/epoch - 20s/step\n",
      "Epoch 12/350\n",
      "9/9 - 176s - loss: 0.0126 - val_loss: 0.0126 - 176s/epoch - 20s/step\n",
      "Epoch 13/350\n",
      "9/9 - 177s - loss: 0.0126 - val_loss: 0.0125 - 177s/epoch - 20s/step\n",
      "Epoch 14/350\n",
      "9/9 - 174s - loss: 0.0125 - val_loss: 0.0125 - 174s/epoch - 19s/step\n",
      "Epoch 15/350\n",
      "9/9 - 180s - loss: 0.0125 - val_loss: 0.0125 - 180s/epoch - 20s/step\n",
      "Epoch 16/350\n",
      "9/9 - 178s - loss: 0.0125 - val_loss: 0.0126 - 178s/epoch - 20s/step\n",
      "Epoch 17/350\n",
      "9/9 - 177s - loss: 0.0125 - val_loss: 0.0126 - 177s/epoch - 20s/step\n",
      "Epoch 18/350\n",
      "9/9 - 177s - loss: 0.0126 - val_loss: 0.0125 - 177s/epoch - 20s/step\n",
      "Epoch 19/350\n",
      "9/9 - 172s - loss: 0.0126 - val_loss: 0.0125 - 172s/epoch - 19s/step\n",
      "Epoch 20/350\n",
      "9/9 - 178s - loss: 0.0126 - val_loss: 0.0126 - 178s/epoch - 20s/step\n",
      "Epoch 21/350\n",
      "9/9 - 176s - loss: 0.0125 - val_loss: 0.0126 - 176s/epoch - 20s/step\n",
      "Epoch 22/350\n",
      "9/9 - 174s - loss: 0.0125 - val_loss: 0.0126 - 174s/epoch - 19s/step\n",
      "Epoch 23/350\n",
      "9/9 - 173s - loss: 0.0125 - val_loss: 0.0125 - 173s/epoch - 19s/step\n",
      "Epoch 24/350\n",
      "9/9 - 179s - loss: 0.0126 - val_loss: 0.0129 - 179s/epoch - 20s/step\n",
      "Epoch 25/350\n",
      "9/9 - 173s - loss: 0.0126 - val_loss: 0.0126 - 173s/epoch - 19s/step\n",
      "Epoch 26/350\n",
      "9/9 - 176s - loss: 0.0125 - val_loss: 0.0129 - 176s/epoch - 20s/step\n",
      "Epoch 27/350\n",
      "9/9 - 178s - loss: 0.0132 - val_loss: 0.0128 - 178s/epoch - 20s/step\n",
      "Epoch 28/350\n",
      "9/9 - 178s - loss: 0.0129 - val_loss: 0.0126 - 178s/epoch - 20s/step\n",
      "Epoch 29/350\n",
      "9/9 - 176s - loss: 0.0124 - val_loss: 0.0121 - 176s/epoch - 20s/step\n",
      "Epoch 30/350\n",
      "9/9 - 177s - loss: 0.0120 - val_loss: 0.0120 - 177s/epoch - 20s/step\n",
      "Epoch 31/350\n",
      "9/9 - 178s - loss: 0.0120 - val_loss: 0.0120 - 178s/epoch - 20s/step\n",
      "Epoch 32/350\n",
      "9/9 - 176s - loss: 0.0118 - val_loss: 0.0116 - 176s/epoch - 20s/step\n",
      "Epoch 33/350\n",
      "9/9 - 179s - loss: 0.0116 - val_loss: 0.0116 - 179s/epoch - 20s/step\n",
      "Epoch 34/350\n",
      "9/9 - 173s - loss: 0.0116 - val_loss: 0.0123 - 173s/epoch - 19s/step\n",
      "Epoch 35/350\n",
      "9/9 - 174s - loss: 0.0119 - val_loss: 0.0116 - 174s/epoch - 19s/step\n",
      "Epoch 36/350\n",
      "9/9 - 177s - loss: 0.0116 - val_loss: 0.0116 - 177s/epoch - 20s/step\n",
      "Epoch 37/350\n",
      "9/9 - 174s - loss: 0.0115 - val_loss: 0.0115 - 174s/epoch - 19s/step\n",
      "Epoch 38/350\n",
      "9/9 - 176s - loss: 0.0116 - val_loss: 0.0119 - 176s/epoch - 20s/step\n",
      "Epoch 39/350\n",
      "9/9 - 174s - loss: 0.0117 - val_loss: 0.0115 - 174s/epoch - 19s/step\n",
      "Epoch 40/350\n",
      "9/9 - 175s - loss: 0.0115 - val_loss: 0.0114 - 175s/epoch - 19s/step\n",
      "Epoch 41/350\n",
      "9/9 - 178s - loss: 0.0114 - val_loss: 0.0114 - 178s/epoch - 20s/step\n",
      "Epoch 42/350\n",
      "9/9 - 175s - loss: 0.0113 - val_loss: 0.0113 - 175s/epoch - 19s/step\n",
      "Epoch 43/350\n",
      "9/9 - 176s - loss: 0.0113 - val_loss: 0.0113 - 176s/epoch - 20s/step\n",
      "Epoch 44/350\n",
      "9/9 - 175s - loss: 0.0113 - val_loss: 0.0114 - 175s/epoch - 19s/step\n",
      "Epoch 45/350\n",
      "9/9 - 178s - loss: 0.0114 - val_loss: 0.0114 - 178s/epoch - 20s/step\n",
      "Epoch 46/350\n",
      "9/9 - 179s - loss: 0.0113 - val_loss: 0.0113 - 179s/epoch - 20s/step\n",
      "Epoch 47/350\n",
      "9/9 - 176s - loss: 0.0113 - val_loss: 0.0113 - 176s/epoch - 20s/step\n",
      "Epoch 48/350\n",
      "9/9 - 176s - loss: 0.0113 - val_loss: 0.0114 - 176s/epoch - 20s/step\n",
      "Epoch 49/350\n",
      "9/9 - 173s - loss: 0.0113 - val_loss: 0.0112 - 173s/epoch - 19s/step\n",
      "Epoch 50/350\n",
      "9/9 - 168s - loss: 0.0113 - val_loss: 0.0112 - 168s/epoch - 19s/step\n",
      "Epoch 51/350\n",
      "9/9 - 174s - loss: 0.0113 - val_loss: 0.0112 - 174s/epoch - 19s/step\n",
      "Epoch 52/350\n",
      "9/9 - 176s - loss: 0.0113 - val_loss: 0.0112 - 176s/epoch - 20s/step\n",
      "Epoch 53/350\n",
      "9/9 - 175s - loss: 0.0112 - val_loss: 0.0112 - 175s/epoch - 19s/step\n",
      "Epoch 54/350\n",
      "9/9 - 175s - loss: 0.0112 - val_loss: 0.0112 - 175s/epoch - 19s/step\n",
      "Epoch 55/350\n",
      "9/9 - 180s - loss: 0.0112 - val_loss: 0.0112 - 180s/epoch - 20s/step\n",
      "Epoch 56/350\n",
      "9/9 - 178s - loss: 0.0112 - val_loss: 0.0112 - 178s/epoch - 20s/step\n",
      "Epoch 57/350\n",
      "9/9 - 174s - loss: 0.0112 - val_loss: 0.0111 - 174s/epoch - 19s/step\n",
      "Epoch 58/350\n",
      "9/9 - 176s - loss: 0.0112 - val_loss: 0.0112 - 176s/epoch - 20s/step\n",
      "Epoch 59/350\n",
      "9/9 - 174s - loss: 0.0112 - val_loss: 0.0113 - 174s/epoch - 19s/step\n",
      "Epoch 60/350\n",
      "9/9 - 178s - loss: 0.0112 - val_loss: 0.0111 - 178s/epoch - 20s/step\n",
      "Epoch 61/350\n",
      "9/9 - 176s - loss: 0.0112 - val_loss: 0.0112 - 176s/epoch - 20s/step\n",
      "Epoch 62/350\n",
      "9/9 - 173s - loss: 0.0112 - val_loss: 0.0113 - 173s/epoch - 19s/step\n",
      "Epoch 63/350\n",
      "9/9 - 174s - loss: 0.0112 - val_loss: 0.0111 - 174s/epoch - 19s/step\n",
      "Epoch 64/350\n",
      "9/9 - 170s - loss: 0.0112 - val_loss: 0.0112 - 170s/epoch - 19s/step\n",
      "Epoch 65/350\n",
      "9/9 - 175s - loss: 0.0112 - val_loss: 0.0111 - 175s/epoch - 19s/step\n",
      "Epoch 66/350\n",
      "9/9 - 178s - loss: 0.0111 - val_loss: 0.0111 - 178s/epoch - 20s/step\n",
      "Epoch 67/350\n",
      "9/9 - 171s - loss: 0.0111 - val_loss: 0.0111 - 171s/epoch - 19s/step\n",
      "Epoch 68/350\n",
      "9/9 - 173s - loss: 0.0111 - val_loss: 0.0112 - 173s/epoch - 19s/step\n",
      "Epoch 69/350\n",
      "9/9 - 178s - loss: 0.0111 - val_loss: 0.0112 - 178s/epoch - 20s/step\n",
      "Epoch 70/350\n",
      "9/9 - 173s - loss: 0.0111 - val_loss: 0.0111 - 173s/epoch - 19s/step\n",
      "Epoch 71/350\n",
      "9/9 - 178s - loss: 0.0111 - val_loss: 0.0111 - 178s/epoch - 20s/step\n",
      "Epoch 72/350\n",
      "9/9 - 178s - loss: 0.0111 - val_loss: 0.0111 - 178s/epoch - 20s/step\n",
      "Epoch 73/350\n",
      "9/9 - 175s - loss: 0.0111 - val_loss: 0.0111 - 175s/epoch - 19s/step\n",
      "Epoch 74/350\n",
      "9/9 - 174s - loss: 0.0111 - val_loss: 0.0112 - 174s/epoch - 19s/step\n",
      "Epoch 75/350\n",
      "9/9 - 173s - loss: 0.0111 - val_loss: 0.0112 - 173s/epoch - 19s/step\n",
      "Epoch 76/350\n",
      "9/9 - 175s - loss: 0.0111 - val_loss: 0.0111 - 175s/epoch - 19s/step\n",
      "Epoch 77/350\n",
      "9/9 - 177s - loss: 0.0111 - val_loss: 0.0111 - 177s/epoch - 20s/step\n",
      "Epoch 78/350\n",
      "9/9 - 176s - loss: 0.0111 - val_loss: 0.0112 - 176s/epoch - 20s/step\n",
      "Epoch 79/350\n",
      "9/9 - 175s - loss: 0.0111 - val_loss: 0.0111 - 175s/epoch - 19s/step\n",
      "Epoch 80/350\n",
      "9/9 - 177s - loss: 0.0111 - val_loss: 0.0112 - 177s/epoch - 20s/step\n",
      "Epoch 81/350\n",
      "9/9 - 180s - loss: 0.0111 - val_loss: 0.0111 - 180s/epoch - 20s/step\n",
      "Epoch 82/350\n",
      "9/9 - 174s - loss: 0.0111 - val_loss: 0.0111 - 174s/epoch - 19s/step\n",
      "Epoch 83/350\n",
      "9/9 - 177s - loss: 0.0111 - val_loss: 0.0110 - 177s/epoch - 20s/step\n",
      "Epoch 84/350\n",
      "9/9 - 176s - loss: 0.0111 - val_loss: 0.0112 - 176s/epoch - 20s/step\n",
      "Epoch 85/350\n",
      "9/9 - 177s - loss: 0.0111 - val_loss: 0.0111 - 177s/epoch - 20s/step\n",
      "Epoch 86/350\n",
      "9/9 - 176s - loss: 0.0110 - val_loss: 0.0111 - 176s/epoch - 20s/step\n",
      "Epoch 87/350\n",
      "9/9 - 174s - loss: 0.0111 - val_loss: 0.0111 - 174s/epoch - 19s/step\n",
      "Epoch 88/350\n",
      "9/9 - 177s - loss: 0.0111 - val_loss: 0.0111 - 177s/epoch - 20s/step\n",
      "Epoch 89/350\n",
      "9/9 - 173s - loss: 0.0111 - val_loss: 0.0111 - 173s/epoch - 19s/step\n",
      "Epoch 90/350\n",
      "9/9 - 178s - loss: 0.0110 - val_loss: 0.0111 - 178s/epoch - 20s/step\n",
      "Epoch 91/350\n",
      "9/9 - 172s - loss: 0.0111 - val_loss: 0.0111 - 172s/epoch - 19s/step\n",
      "Epoch 92/350\n",
      "9/9 - 175s - loss: 0.0111 - val_loss: 0.0111 - 175s/epoch - 19s/step\n",
      "Epoch 93/350\n",
      "9/9 - 174s - loss: 0.0111 - val_loss: 0.0111 - 174s/epoch - 19s/step\n",
      "Epoch 94/350\n",
      "9/9 - 174s - loss: 0.0110 - val_loss: 0.0111 - 174s/epoch - 19s/step\n",
      "Epoch 95/350\n",
      "9/9 - 171s - loss: 0.0111 - val_loss: 0.0111 - 171s/epoch - 19s/step\n",
      "Epoch 96/350\n",
      "9/9 - 173s - loss: 0.0111 - val_loss: 0.0111 - 173s/epoch - 19s/step\n",
      "Epoch 97/350\n",
      "9/9 - 177s - loss: 0.0111 - val_loss: 0.0111 - 177s/epoch - 20s/step\n",
      "Epoch 98/350\n",
      "9/9 - 176s - loss: 0.0111 - val_loss: 0.0110 - 176s/epoch - 20s/step\n",
      "Epoch 99/350\n",
      "9/9 - 173s - loss: 0.0111 - val_loss: 0.0111 - 173s/epoch - 19s/step\n",
      "Epoch 100/350\n",
      "9/9 - 178s - loss: 0.0111 - val_loss: 0.0110 - 178s/epoch - 20s/step\n",
      "Epoch 101/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 - 171s - loss: 0.0110 - val_loss: 0.0112 - 171s/epoch - 19s/step\n",
      "Epoch 102/350\n",
      "9/9 - 171s - loss: 0.0111 - val_loss: 0.0110 - 171s/epoch - 19s/step\n",
      "Epoch 103/350\n",
      "9/9 - 178s - loss: 0.0110 - val_loss: 0.0111 - 178s/epoch - 20s/step\n",
      "Epoch 104/350\n",
      "9/9 - 171s - loss: 0.0110 - val_loss: 0.0111 - 171s/epoch - 19s/step\n",
      "Epoch 105/350\n",
      "9/9 - 167s - loss: 0.0110 - val_loss: 0.0111 - 167s/epoch - 19s/step\n",
      "Epoch 106/350\n",
      "9/9 - 174s - loss: 0.0111 - val_loss: 0.0111 - 174s/epoch - 19s/step\n",
      "Epoch 107/350\n",
      "9/9 - 178s - loss: 0.0110 - val_loss: 0.0111 - 178s/epoch - 20s/step\n",
      "Epoch 108/350\n",
      "9/9 - 173s - loss: 0.0110 - val_loss: 0.0111 - 173s/epoch - 19s/step\n",
      "Epoch 109/350\n",
      "9/9 - 174s - loss: 0.0110 - val_loss: 0.0111 - 174s/epoch - 19s/step\n",
      "Epoch 110/350\n",
      "9/9 - 179s - loss: 0.0110 - val_loss: 0.0111 - 179s/epoch - 20s/step\n",
      "Epoch 111/350\n",
      "9/9 - 172s - loss: 0.0111 - val_loss: 0.0111 - 172s/epoch - 19s/step\n",
      "Epoch 112/350\n",
      "9/9 - 173s - loss: 0.0110 - val_loss: 0.0111 - 173s/epoch - 19s/step\n",
      "Epoch 113/350\n",
      "9/9 - 174s - loss: 0.0110 - val_loss: 0.0110 - 174s/epoch - 19s/step\n",
      "Epoch 114/350\n",
      "9/9 - 176s - loss: 0.0110 - val_loss: 0.0111 - 176s/epoch - 20s/step\n",
      "Epoch 115/350\n",
      "9/9 - 171s - loss: 0.0111 - val_loss: 0.0111 - 171s/epoch - 19s/step\n",
      "Epoch 116/350\n",
      "9/9 - 162s - loss: 0.0110 - val_loss: 0.0111 - 162s/epoch - 18s/step\n",
      "Epoch 117/350\n",
      "9/9 - 173s - loss: 0.0110 - val_loss: 0.0110 - 173s/epoch - 19s/step\n",
      "Epoch 118/350\n",
      "9/9 - 174s - loss: 0.0110 - val_loss: 0.0110 - 174s/epoch - 19s/step\n",
      "Epoch 119/350\n",
      "9/9 - 170s - loss: 0.0110 - val_loss: 0.0110 - 170s/epoch - 19s/step\n",
      "Epoch 120/350\n",
      "9/9 - 175s - loss: 0.0110 - val_loss: 0.0110 - 175s/epoch - 19s/step\n",
      "Epoch 121/350\n",
      "9/9 - 173s - loss: 0.0110 - val_loss: 0.0111 - 173s/epoch - 19s/step\n",
      "Epoch 122/350\n",
      "9/9 - 176s - loss: 0.0111 - val_loss: 0.0111 - 176s/epoch - 20s/step\n",
      "Epoch 123/350\n",
      "9/9 - 161s - loss: 0.0111 - val_loss: 0.0111 - 161s/epoch - 18s/step\n",
      "Epoch 124/350\n",
      "9/9 - 173s - loss: 0.0111 - val_loss: 0.0111 - 173s/epoch - 19s/step\n",
      "Epoch 125/350\n",
      "9/9 - 171s - loss: 0.0110 - val_loss: 0.0111 - 171s/epoch - 19s/step\n",
      "Epoch 126/350\n",
      "9/9 - 175s - loss: 0.0112 - val_loss: 0.0111 - 175s/epoch - 19s/step\n",
      "Epoch 127/350\n",
      "9/9 - 173s - loss: 0.0111 - val_loss: 0.0111 - 173s/epoch - 19s/step\n",
      "Epoch 128/350\n",
      "9/9 - 175s - loss: 0.0111 - val_loss: 0.0111 - 175s/epoch - 19s/step\n",
      "Epoch 129/350\n",
      "9/9 - 174s - loss: 0.0111 - val_loss: 0.0111 - 174s/epoch - 19s/step\n",
      "Epoch 130/350\n",
      "9/9 - 178s - loss: 0.0110 - val_loss: 0.0110 - 178s/epoch - 20s/step\n",
      "Epoch 131/350\n",
      "9/9 - 172s - loss: 0.0110 - val_loss: 0.0110 - 172s/epoch - 19s/step\n",
      "Epoch 132/350\n",
      "9/9 - 173s - loss: 0.0110 - val_loss: 0.0110 - 173s/epoch - 19s/step\n",
      "Epoch 133/350\n",
      "9/9 - 174s - loss: 0.0110 - val_loss: 0.0112 - 174s/epoch - 19s/step\n",
      "Epoch 134/350\n",
      "9/9 - 177s - loss: 0.0111 - val_loss: 0.0112 - 177s/epoch - 20s/step\n",
      "Epoch 135/350\n",
      "9/9 - 172s - loss: 0.0111 - val_loss: 0.0111 - 172s/epoch - 19s/step\n",
      "Epoch 136/350\n",
      "9/9 - 181s - loss: 0.0111 - val_loss: 0.0110 - 181s/epoch - 20s/step\n",
      "Epoch 137/350\n",
      "9/9 - 184s - loss: 0.0110 - val_loss: 0.0110 - 184s/epoch - 20s/step\n",
      "Epoch 138/350\n",
      "9/9 - 178s - loss: 0.0110 - val_loss: 0.0110 - 178s/epoch - 20s/step\n",
      "Epoch 139/350\n",
      "9/9 - 176s - loss: 0.0110 - val_loss: 0.0110 - 176s/epoch - 20s/step\n",
      "Epoch 140/350\n",
      "9/9 - 180s - loss: 0.0111 - val_loss: 0.0112 - 180s/epoch - 20s/step\n",
      "Epoch 141/350\n",
      "9/9 - 177s - loss: 0.0111 - val_loss: 0.0111 - 177s/epoch - 20s/step\n",
      "Epoch 142/350\n",
      "9/9 - 174s - loss: 0.0110 - val_loss: 0.0110 - 174s/epoch - 19s/step\n",
      "Epoch 143/350\n",
      "9/9 - 177s - loss: 0.0110 - val_loss: 0.0110 - 177s/epoch - 20s/step\n",
      "Epoch 144/350\n",
      "9/9 - 175s - loss: 0.0110 - val_loss: 0.0110 - 175s/epoch - 19s/step\n",
      "Epoch 145/350\n",
      "9/9 - 179s - loss: 0.0110 - val_loss: 0.0110 - 179s/epoch - 20s/step\n",
      "Epoch 146/350\n",
      "9/9 - 175s - loss: 0.0110 - val_loss: 0.0110 - 175s/epoch - 19s/step\n",
      "Epoch 147/350\n",
      "9/9 - 175s - loss: 0.0110 - val_loss: 0.0110 - 175s/epoch - 19s/step\n",
      "Epoch 148/350\n",
      "9/9 - 174s - loss: 0.0110 - val_loss: 0.0110 - 174s/epoch - 19s/step\n",
      "Epoch 149/350\n",
      "9/9 - 180s - loss: 0.0110 - val_loss: 0.0111 - 180s/epoch - 20s/step\n",
      "Epoch 150/350\n",
      "9/9 - 174s - loss: 0.0112 - val_loss: 0.0112 - 174s/epoch - 19s/step\n",
      "Epoch 151/350\n",
      "9/9 - 175s - loss: 0.0110 - val_loss: 0.0110 - 175s/epoch - 19s/step\n",
      "Epoch 152/350\n",
      "9/9 - 179s - loss: 0.0110 - val_loss: 0.0110 - 179s/epoch - 20s/step\n",
      "Epoch 153/350\n",
      "9/9 - 179s - loss: 0.0110 - val_loss: 0.0110 - 179s/epoch - 20s/step\n",
      "Epoch 154/350\n",
      "9/9 - 180s - loss: 0.0110 - val_loss: 0.0111 - 180s/epoch - 20s/step\n",
      "Epoch 155/350\n",
      "9/9 - 174s - loss: 0.0110 - val_loss: 0.0110 - 174s/epoch - 19s/step\n",
      "Epoch 156/350\n",
      "9/9 - 186s - loss: 0.0110 - val_loss: 0.0110 - 186s/epoch - 21s/step\n",
      "Epoch 157/350\n",
      "9/9 - 185s - loss: 0.0110 - val_loss: 0.0110 - 185s/epoch - 21s/step\n",
      "Epoch 158/350\n",
      "9/9 - 189s - loss: 0.0109 - val_loss: 0.0110 - 189s/epoch - 21s/step\n",
      "Epoch 159/350\n",
      "9/9 - 177s - loss: 0.0110 - val_loss: 0.0111 - 177s/epoch - 20s/step\n",
      "Epoch 160/350\n",
      "9/9 - 188s - loss: 0.0110 - val_loss: 0.0111 - 188s/epoch - 21s/step\n",
      "Epoch 161/350\n",
      "9/9 - 175s - loss: 0.0110 - val_loss: 0.0111 - 175s/epoch - 19s/step\n",
      "Epoch 162/350\n",
      "9/9 - 178s - loss: 0.0110 - val_loss: 0.0110 - 178s/epoch - 20s/step\n",
      "Epoch 163/350\n",
      "9/9 - 177s - loss: 0.0109 - val_loss: 0.0110 - 177s/epoch - 20s/step\n",
      "Epoch 164/350\n",
      "9/9 - 172s - loss: 0.0109 - val_loss: 0.0109 - 172s/epoch - 19s/step\n",
      "Epoch 165/350\n",
      "9/9 - 175s - loss: 0.0109 - val_loss: 0.0110 - 175s/epoch - 19s/step\n",
      "Epoch 166/350\n",
      "9/9 - 180s - loss: 0.0110 - val_loss: 0.0113 - 180s/epoch - 20s/step\n",
      "Epoch 167/350\n",
      "9/9 - 177s - loss: 0.0111 - val_loss: 0.0111 - 177s/epoch - 20s/step\n",
      "Epoch 168/350\n",
      "9/9 - 182s - loss: 0.0110 - val_loss: 0.0113 - 182s/epoch - 20s/step\n",
      "Epoch 169/350\n",
      "9/9 - 174s - loss: 0.0111 - val_loss: 0.0110 - 174s/epoch - 19s/step\n",
      "Epoch 170/350\n",
      "9/9 - 178s - loss: 0.0110 - val_loss: 0.0110 - 178s/epoch - 20s/step\n",
      "Epoch 171/350\n",
      "9/9 - 174s - loss: 0.0109 - val_loss: 0.0109 - 174s/epoch - 19s/step\n",
      "Epoch 172/350\n",
      "9/9 - 177s - loss: 0.0109 - val_loss: 0.0109 - 177s/epoch - 20s/step\n",
      "Epoch 173/350\n",
      "9/9 - 175s - loss: 0.0112 - val_loss: 0.0117 - 175s/epoch - 19s/step\n",
      "Epoch 174/350\n",
      "9/9 - 176s - loss: 0.0114 - val_loss: 0.0116 - 176s/epoch - 20s/step\n",
      "Epoch 175/350\n",
      "9/9 - 174s - loss: 0.0114 - val_loss: 0.0114 - 174s/epoch - 19s/step\n",
      "Epoch 176/350\n",
      "9/9 - 177s - loss: 0.0112 - val_loss: 0.0112 - 177s/epoch - 20s/step\n",
      "Epoch 177/350\n",
      "9/9 - 174s - loss: 0.0110 - val_loss: 0.0110 - 174s/epoch - 19s/step\n",
      "Epoch 178/350\n",
      "9/9 - 175s - loss: 0.0109 - val_loss: 0.0109 - 175s/epoch - 19s/step\n",
      "Epoch 179/350\n",
      "9/9 - 176s - loss: 0.0110 - val_loss: 0.0110 - 176s/epoch - 20s/step\n",
      "Epoch 180/350\n",
      "9/9 - 171s - loss: 0.0109 - val_loss: 0.0109 - 171s/epoch - 19s/step\n",
      "Epoch 181/350\n",
      "9/9 - 167s - loss: 0.0109 - val_loss: 0.0110 - 167s/epoch - 19s/step\n",
      "Epoch 182/350\n",
      "9/9 - 174s - loss: 0.0109 - val_loss: 0.0109 - 174s/epoch - 19s/step\n",
      "Epoch 183/350\n",
      "9/9 - 174s - loss: 0.0109 - val_loss: 0.0108 - 174s/epoch - 19s/step\n",
      "Epoch 184/350\n",
      "9/9 - 179s - loss: 0.0109 - val_loss: 0.0109 - 179s/epoch - 20s/step\n",
      "Epoch 185/350\n",
      "9/9 - 176s - loss: 0.0109 - val_loss: 0.0108 - 176s/epoch - 20s/step\n",
      "Epoch 186/350\n",
      "9/9 - 174s - loss: 0.0108 - val_loss: 0.0108 - 174s/epoch - 19s/step\n",
      "Epoch 187/350\n",
      "9/9 - 173s - loss: 0.0109 - val_loss: 0.0110 - 173s/epoch - 19s/step\n",
      "Epoch 188/350\n",
      "9/9 - 175s - loss: 0.0109 - val_loss: 0.0108 - 175s/epoch - 19s/step\n",
      "Epoch 189/350\n",
      "9/9 - 170s - loss: 0.0108 - val_loss: 0.0107 - 170s/epoch - 19s/step\n",
      "Epoch 190/350\n",
      "9/9 - 166s - loss: 0.0107 - val_loss: 0.0107 - 166s/epoch - 18s/step\n",
      "Epoch 191/350\n",
      "9/9 - 171s - loss: 0.0107 - val_loss: 0.0107 - 171s/epoch - 19s/step\n",
      "Epoch 192/350\n",
      "9/9 - 174s - loss: 0.0107 - val_loss: 0.0108 - 174s/epoch - 19s/step\n",
      "Epoch 193/350\n",
      "9/9 - 174s - loss: 0.0108 - val_loss: 0.0107 - 174s/epoch - 19s/step\n",
      "Epoch 194/350\n",
      "9/9 - 177s - loss: 0.0107 - val_loss: 0.0107 - 177s/epoch - 20s/step\n",
      "Epoch 195/350\n",
      "9/9 - 173s - loss: 0.0106 - val_loss: 0.0107 - 173s/epoch - 19s/step\n",
      "Epoch 196/350\n",
      "9/9 - 170s - loss: 0.0107 - val_loss: 0.0107 - 170s/epoch - 19s/step\n",
      "Epoch 197/350\n",
      "9/9 - 168s - loss: 0.0107 - val_loss: 0.0107 - 168s/epoch - 19s/step\n",
      "Epoch 198/350\n",
      "9/9 - 179s - loss: 0.0106 - val_loss: 0.0106 - 179s/epoch - 20s/step\n",
      "Epoch 199/350\n",
      "9/9 - 176s - loss: 0.0106 - val_loss: 0.0108 - 176s/epoch - 20s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/350\n",
      "9/9 - 175s - loss: 0.0108 - val_loss: 0.0107 - 175s/epoch - 19s/step\n",
      "Epoch 201/350\n",
      "9/9 - 176s - loss: 0.0106 - val_loss: 0.0106 - 176s/epoch - 20s/step\n",
      "Epoch 202/350\n",
      "9/9 - 172s - loss: 0.0106 - val_loss: 0.0106 - 172s/epoch - 19s/step\n",
      "Epoch 203/350\n",
      "9/9 - 175s - loss: 0.0106 - val_loss: 0.0106 - 175s/epoch - 19s/step\n",
      "Epoch 204/350\n",
      "9/9 - 177s - loss: 0.0106 - val_loss: 0.0106 - 177s/epoch - 20s/step\n",
      "Epoch 205/350\n",
      "9/9 - 168s - loss: 0.0105 - val_loss: 0.0105 - 168s/epoch - 19s/step\n",
      "Epoch 206/350\n",
      "9/9 - 174s - loss: 0.0106 - val_loss: 0.0107 - 174s/epoch - 19s/step\n",
      "Epoch 207/350\n",
      "9/9 - 176s - loss: 0.0106 - val_loss: 0.0105 - 176s/epoch - 20s/step\n",
      "Epoch 208/350\n",
      "9/9 - 179s - loss: 0.0105 - val_loss: 0.0106 - 179s/epoch - 20s/step\n",
      "Epoch 209/350\n",
      "9/9 - 182s - loss: 0.0107 - val_loss: 0.0106 - 182s/epoch - 20s/step\n",
      "Epoch 210/350\n",
      "9/9 - 178s - loss: 0.0106 - val_loss: 0.0106 - 178s/epoch - 20s/step\n",
      "Epoch 211/350\n",
      "9/9 - 178s - loss: 0.0105 - val_loss: 0.0106 - 178s/epoch - 20s/step\n",
      "Epoch 212/350\n",
      "9/9 - 175s - loss: 0.0106 - val_loss: 0.0105 - 175s/epoch - 19s/step\n",
      "Epoch 213/350\n",
      "9/9 - 181s - loss: 0.0105 - val_loss: 0.0106 - 181s/epoch - 20s/step\n",
      "Epoch 214/350\n",
      "9/9 - 177s - loss: 0.0107 - val_loss: 0.0106 - 177s/epoch - 20s/step\n",
      "Epoch 215/350\n",
      "9/9 - 180s - loss: 0.0106 - val_loss: 0.0105 - 180s/epoch - 20s/step\n",
      "Epoch 216/350\n",
      "9/9 - 182s - loss: 0.0105 - val_loss: 0.0106 - 182s/epoch - 20s/step\n",
      "Epoch 217/350\n",
      "9/9 - 187s - loss: 0.0105 - val_loss: 0.0105 - 187s/epoch - 21s/step\n",
      "Epoch 218/350\n",
      "9/9 - 200s - loss: 0.0105 - val_loss: 0.0105 - 200s/epoch - 22s/step\n",
      "Epoch 219/350\n",
      "9/9 - 176s - loss: 0.0105 - val_loss: 0.0105 - 176s/epoch - 20s/step\n",
      "Epoch 220/350\n",
      "9/9 - 194s - loss: 0.0105 - val_loss: 0.0105 - 194s/epoch - 22s/step\n",
      "Epoch 221/350\n",
      "9/9 - 179s - loss: 0.0104 - val_loss: 0.0105 - 179s/epoch - 20s/step\n",
      "Epoch 222/350\n",
      "9/9 - 180s - loss: 0.0105 - val_loss: 0.0105 - 180s/epoch - 20s/step\n",
      "Epoch 223/350\n",
      "9/9 - 183s - loss: 0.0105 - val_loss: 0.0106 - 183s/epoch - 20s/step\n",
      "Epoch 224/350\n",
      "9/9 - 207s - loss: 0.0105 - val_loss: 0.0105 - 207s/epoch - 23s/step\n",
      "Epoch 225/350\n",
      "9/9 - 202s - loss: 0.0104 - val_loss: 0.0105 - 202s/epoch - 22s/step\n",
      "Epoch 226/350\n",
      "9/9 - 184s - loss: 0.0104 - val_loss: 0.0104 - 184s/epoch - 20s/step\n",
      "Epoch 227/350\n",
      "9/9 - 194s - loss: 0.0104 - val_loss: 0.0104 - 194s/epoch - 22s/step\n",
      "Epoch 228/350\n",
      "9/9 - 188s - loss: 0.0105 - val_loss: 0.0105 - 188s/epoch - 21s/step\n",
      "Epoch 229/350\n",
      "9/9 - 185s - loss: 0.0105 - val_loss: 0.0104 - 185s/epoch - 21s/step\n",
      "Epoch 230/350\n",
      "9/9 - 191s - loss: 0.0104 - val_loss: 0.0104 - 191s/epoch - 21s/step\n",
      "Epoch 231/350\n",
      "9/9 - 194s - loss: 0.0104 - val_loss: 0.0106 - 194s/epoch - 22s/step\n",
      "Epoch 232/350\n",
      "9/9 - 198s - loss: 0.0104 - val_loss: 0.0104 - 198s/epoch - 22s/step\n",
      "Epoch 233/350\n",
      "9/9 - 190s - loss: 0.0104 - val_loss: 0.0104 - 190s/epoch - 21s/step\n",
      "Epoch 234/350\n",
      "9/9 - 218s - loss: 0.0104 - val_loss: 0.0105 - 218s/epoch - 24s/step\n",
      "Epoch 235/350\n",
      "9/9 - 212s - loss: 0.0104 - val_loss: 0.0104 - 212s/epoch - 24s/step\n",
      "Epoch 236/350\n",
      "9/9 - 219s - loss: 0.0104 - val_loss: 0.0105 - 219s/epoch - 24s/step\n",
      "Epoch 237/350\n",
      "9/9 - 186s - loss: 0.0104 - val_loss: 0.0104 - 186s/epoch - 21s/step\n",
      "Epoch 238/350\n",
      "9/9 - 202s - loss: 0.0104 - val_loss: 0.0104 - 202s/epoch - 22s/step\n",
      "Epoch 239/350\n",
      "9/9 - 202s - loss: 0.0104 - val_loss: 0.0104 - 202s/epoch - 22s/step\n",
      "Epoch 240/350\n",
      "9/9 - 214s - loss: 0.0104 - val_loss: 0.0104 - 214s/epoch - 24s/step\n",
      "Epoch 241/350\n",
      "9/9 - 232s - loss: 0.0104 - val_loss: 0.0104 - 232s/epoch - 26s/step\n",
      "Epoch 242/350\n",
      "9/9 - 224s - loss: 0.0104 - val_loss: 0.0104 - 224s/epoch - 25s/step\n",
      "Epoch 243/350\n",
      "9/9 - 212s - loss: 0.0105 - val_loss: 0.0104 - 212s/epoch - 24s/step\n",
      "Epoch 244/350\n",
      "9/9 - 179s - loss: 0.0104 - val_loss: 0.0104 - 179s/epoch - 20s/step\n",
      "Epoch 245/350\n",
      "9/9 - 200s - loss: 0.0104 - val_loss: 0.0104 - 200s/epoch - 22s/step\n",
      "Epoch 246/350\n",
      "9/9 - 182s - loss: 0.0104 - val_loss: 0.0104 - 182s/epoch - 20s/step\n",
      "Epoch 247/350\n",
      "9/9 - 180s - loss: 0.0104 - val_loss: 0.0104 - 180s/epoch - 20s/step\n",
      "Epoch 248/350\n",
      "9/9 - 178s - loss: 0.0104 - val_loss: 0.0104 - 178s/epoch - 20s/step\n",
      "Epoch 249/350\n",
      "9/9 - 179s - loss: 0.0104 - val_loss: 0.0104 - 179s/epoch - 20s/step\n",
      "Epoch 250/350\n",
      "9/9 - 195s - loss: 0.0104 - val_loss: 0.0104 - 195s/epoch - 22s/step\n",
      "Epoch 251/350\n",
      "9/9 - 180s - loss: 0.0104 - val_loss: 0.0104 - 180s/epoch - 20s/step\n",
      "Epoch 252/350\n",
      "9/9 - 183s - loss: 0.0104 - val_loss: 0.0104 - 183s/epoch - 20s/step\n",
      "Epoch 253/350\n",
      "9/9 - 182s - loss: 0.0104 - val_loss: 0.0104 - 182s/epoch - 20s/step\n",
      "Epoch 254/350\n",
      "9/9 - 187s - loss: 0.0104 - val_loss: 0.0104 - 187s/epoch - 21s/step\n",
      "Epoch 255/350\n",
      "9/9 - 182s - loss: 0.0104 - val_loss: 0.0104 - 182s/epoch - 20s/step\n",
      "Epoch 256/350\n",
      "9/9 - 181s - loss: 0.0104 - val_loss: 0.0104 - 181s/epoch - 20s/step\n",
      "Epoch 257/350\n",
      "9/9 - 175s - loss: 0.0104 - val_loss: 0.0104 - 175s/epoch - 19s/step\n",
      "Epoch 258/350\n",
      "9/9 - 184s - loss: 0.0103 - val_loss: 0.0104 - 184s/epoch - 20s/step\n",
      "Epoch 259/350\n",
      "9/9 - 182s - loss: 0.0103 - val_loss: 0.0104 - 182s/epoch - 20s/step\n",
      "Epoch 260/350\n",
      "9/9 - 181s - loss: 0.0104 - val_loss: 0.0105 - 181s/epoch - 20s/step\n",
      "Epoch 261/350\n",
      "9/9 - 176s - loss: 0.0104 - val_loss: 0.0104 - 176s/epoch - 20s/step\n",
      "Epoch 262/350\n",
      "9/9 - 178s - loss: 0.0104 - val_loss: 0.0104 - 178s/epoch - 20s/step\n",
      "Epoch 263/350\n",
      "9/9 - 175s - loss: 0.0104 - val_loss: 0.0104 - 175s/epoch - 19s/step\n",
      "Epoch 264/350\n",
      "9/9 - 183s - loss: 0.0103 - val_loss: 0.0104 - 183s/epoch - 20s/step\n",
      "Epoch 265/350\n",
      "9/9 - 183s - loss: 0.0104 - val_loss: 0.0104 - 183s/epoch - 20s/step\n",
      "Epoch 266/350\n",
      "9/9 - 176s - loss: 0.0104 - val_loss: 0.0104 - 176s/epoch - 20s/step\n",
      "Epoch 267/350\n",
      "9/9 - 184s - loss: 0.0103 - val_loss: 0.0104 - 184s/epoch - 20s/step\n",
      "Epoch 268/350\n",
      "9/9 - 177s - loss: 0.0103 - val_loss: 0.0104 - 177s/epoch - 20s/step\n",
      "Epoch 269/350\n",
      "9/9 - 177s - loss: 0.0104 - val_loss: 0.0104 - 177s/epoch - 20s/step\n",
      "Epoch 270/350\n",
      "9/9 - 187s - loss: 0.0103 - val_loss: 0.0103 - 187s/epoch - 21s/step\n",
      "Epoch 271/350\n",
      "9/9 - 181s - loss: 0.0103 - val_loss: 0.0104 - 181s/epoch - 20s/step\n",
      "Epoch 272/350\n",
      "9/9 - 184s - loss: 0.0104 - val_loss: 0.0105 - 184s/epoch - 20s/step\n",
      "Epoch 273/350\n",
      "9/9 - 179s - loss: 0.0104 - val_loss: 0.0104 - 179s/epoch - 20s/step\n",
      "Epoch 274/350\n",
      "9/9 - 178s - loss: 0.0104 - val_loss: 0.0104 - 178s/epoch - 20s/step\n",
      "Epoch 275/350\n",
      "9/9 - 180s - loss: 0.0103 - val_loss: 0.0103 - 180s/epoch - 20s/step\n",
      "Epoch 276/350\n",
      "9/9 - 180s - loss: 0.0104 - val_loss: 0.0104 - 180s/epoch - 20s/step\n",
      "Epoch 277/350\n",
      "9/9 - 183s - loss: 0.0104 - val_loss: 0.0104 - 183s/epoch - 20s/step\n",
      "Epoch 278/350\n",
      "9/9 - 180s - loss: 0.0104 - val_loss: 0.0103 - 180s/epoch - 20s/step\n",
      "Epoch 279/350\n",
      "9/9 - 187s - loss: 0.0103 - val_loss: 0.0104 - 187s/epoch - 21s/step\n",
      "Epoch 280/350\n",
      "9/9 - 175s - loss: 0.0103 - val_loss: 0.0104 - 175s/epoch - 19s/step\n",
      "Epoch 281/350\n",
      "9/9 - 181s - loss: 0.0103 - val_loss: 0.0104 - 181s/epoch - 20s/step\n",
      "Epoch 282/350\n",
      "9/9 - 182s - loss: 0.0103 - val_loss: 0.0104 - 182s/epoch - 20s/step\n",
      "Epoch 283/350\n",
      "9/9 - 183s - loss: 0.0104 - val_loss: 0.0104 - 183s/epoch - 20s/step\n",
      "Epoch 284/350\n",
      "9/9 - 182s - loss: 0.0104 - val_loss: 0.0104 - 182s/epoch - 20s/step\n",
      "Epoch 285/350\n",
      "9/9 - 180s - loss: 0.0103 - val_loss: 0.0104 - 180s/epoch - 20s/step\n",
      "Epoch 286/350\n",
      "9/9 - 180s - loss: 0.0103 - val_loss: 0.0104 - 180s/epoch - 20s/step\n",
      "Epoch 287/350\n",
      "9/9 - 175s - loss: 0.0103 - val_loss: 0.0104 - 175s/epoch - 19s/step\n",
      "Epoch 288/350\n",
      "9/9 - 181s - loss: 0.0103 - val_loss: 0.0104 - 181s/epoch - 20s/step\n",
      "Epoch 289/350\n",
      "9/9 - 174s - loss: 0.0104 - val_loss: 0.0104 - 174s/epoch - 19s/step\n",
      "Epoch 290/350\n",
      "9/9 - 177s - loss: 0.0103 - val_loss: 0.0104 - 177s/epoch - 20s/step\n",
      "Epoch 291/350\n",
      "9/9 - 175s - loss: 0.0103 - val_loss: 0.0104 - 175s/epoch - 19s/step\n",
      "Epoch 292/350\n",
      "9/9 - 180s - loss: 0.0103 - val_loss: 0.0104 - 180s/epoch - 20s/step\n",
      "Epoch 293/350\n",
      "9/9 - 180s - loss: 0.0103 - val_loss: 0.0104 - 180s/epoch - 20s/step\n",
      "Epoch 294/350\n",
      "9/9 - 181s - loss: 0.0103 - val_loss: 0.0103 - 181s/epoch - 20s/step\n",
      "Epoch 295/350\n",
      "9/9 - 184s - loss: 0.0104 - val_loss: 0.0104 - 184s/epoch - 20s/step\n",
      "Epoch 296/350\n",
      "9/9 - 176s - loss: 0.0103 - val_loss: 0.0104 - 176s/epoch - 20s/step\n",
      "Epoch 297/350\n",
      "9/9 - 179s - loss: 0.0103 - val_loss: 0.0104 - 179s/epoch - 20s/step\n",
      "Epoch 298/350\n",
      "9/9 - 176s - loss: 0.0103 - val_loss: 0.0103 - 176s/epoch - 20s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/350\n",
      "9/9 - 176s - loss: 0.0103 - val_loss: 0.0104 - 176s/epoch - 20s/step\n",
      "Epoch 300/350\n",
      "9/9 - 179s - loss: 0.0104 - val_loss: 0.0104 - 179s/epoch - 20s/step\n",
      "Epoch 301/350\n",
      "9/9 - 178s - loss: 0.0104 - val_loss: 0.0104 - 178s/epoch - 20s/step\n",
      "Epoch 302/350\n",
      "9/9 - 178s - loss: 0.0103 - val_loss: 0.0103 - 178s/epoch - 20s/step\n",
      "Epoch 303/350\n",
      "9/9 - 181s - loss: 0.0103 - val_loss: 0.0103 - 181s/epoch - 20s/step\n",
      "Epoch 304/350\n",
      "9/9 - 174s - loss: 0.0103 - val_loss: 0.0104 - 174s/epoch - 19s/step\n",
      "Epoch 305/350\n",
      "9/9 - 181s - loss: 0.0103 - val_loss: 0.0103 - 181s/epoch - 20s/step\n",
      "Epoch 306/350\n",
      "9/9 - 173s - loss: 0.0103 - val_loss: 0.0103 - 173s/epoch - 19s/step\n",
      "Epoch 307/350\n",
      "9/9 - 180s - loss: 0.0103 - val_loss: 0.0105 - 180s/epoch - 20s/step\n",
      "Epoch 308/350\n",
      "9/9 - 179s - loss: 0.0104 - val_loss: 0.0104 - 179s/epoch - 20s/step\n",
      "Epoch 309/350\n",
      "9/9 - 176s - loss: 0.0103 - val_loss: 0.0103 - 176s/epoch - 20s/step\n",
      "Epoch 310/350\n",
      "9/9 - 180s - loss: 0.0103 - val_loss: 0.0104 - 180s/epoch - 20s/step\n",
      "Epoch 311/350\n",
      "9/9 - 177s - loss: 0.0103 - val_loss: 0.0103 - 177s/epoch - 20s/step\n",
      "Epoch 312/350\n",
      "9/9 - 177s - loss: 0.0103 - val_loss: 0.0104 - 177s/epoch - 20s/step\n",
      "Epoch 313/350\n",
      "9/9 - 179s - loss: 0.0103 - val_loss: 0.0104 - 179s/epoch - 20s/step\n",
      "Epoch 314/350\n",
      "9/9 - 183s - loss: 0.0103 - val_loss: 0.0103 - 183s/epoch - 20s/step\n",
      "Epoch 315/350\n",
      "9/9 - 178s - loss: 0.0103 - val_loss: 0.0104 - 178s/epoch - 20s/step\n",
      "Epoch 316/350\n",
      "9/9 - 182s - loss: 0.0103 - val_loss: 0.0103 - 182s/epoch - 20s/step\n",
      "Epoch 317/350\n",
      "9/9 - 182s - loss: 0.0103 - val_loss: 0.0110 - 182s/epoch - 20s/step\n",
      "Epoch 318/350\n",
      "9/9 - 181s - loss: 0.0117 - val_loss: 0.0109 - 181s/epoch - 20s/step\n",
      "Epoch 319/350\n",
      "9/9 - 183s - loss: 0.0108 - val_loss: 0.0108 - 183s/epoch - 20s/step\n",
      "Epoch 320/350\n",
      "9/9 - 180s - loss: 0.0108 - val_loss: 0.0105 - 180s/epoch - 20s/step\n",
      "Epoch 321/350\n",
      "9/9 - 185s - loss: 0.0107 - val_loss: 0.0107 - 185s/epoch - 21s/step\n",
      "Epoch 322/350\n",
      "9/9 - 181s - loss: 0.0105 - val_loss: 0.0104 - 181s/epoch - 20s/step\n",
      "Epoch 323/350\n",
      "9/9 - 178s - loss: 0.0104 - val_loss: 0.0104 - 178s/epoch - 20s/step\n",
      "Epoch 324/350\n",
      "9/9 - 171s - loss: 0.0104 - val_loss: 0.0103 - 171s/epoch - 19s/step\n",
      "Epoch 325/350\n",
      "9/9 - 182s - loss: 0.0103 - val_loss: 0.0104 - 182s/epoch - 20s/step\n",
      "Epoch 326/350\n",
      "9/9 - 176s - loss: 0.0104 - val_loss: 0.0103 - 176s/epoch - 20s/step\n",
      "Epoch 327/350\n",
      "9/9 - 178s - loss: 0.0104 - val_loss: 0.0104 - 178s/epoch - 20s/step\n",
      "Epoch 328/350\n",
      "9/9 - 182s - loss: 0.0103 - val_loss: 0.0103 - 182s/epoch - 20s/step\n",
      "Epoch 329/350\n",
      "9/9 - 176s - loss: 0.0103 - val_loss: 0.0104 - 176s/epoch - 20s/step\n",
      "Epoch 330/350\n",
      "9/9 - 179s - loss: 0.0103 - val_loss: 0.0103 - 179s/epoch - 20s/step\n",
      "Epoch 331/350\n",
      "9/9 - 179s - loss: 0.0103 - val_loss: 0.0104 - 179s/epoch - 20s/step\n",
      "Epoch 332/350\n",
      "9/9 - 181s - loss: 0.0103 - val_loss: 0.0103 - 181s/epoch - 20s/step\n",
      "Epoch 333/350\n",
      "9/9 - 176s - loss: 0.0103 - val_loss: 0.0103 - 176s/epoch - 20s/step\n",
      "Epoch 334/350\n",
      "9/9 - 173s - loss: 0.0103 - val_loss: 0.0104 - 173s/epoch - 19s/step\n",
      "Epoch 335/350\n",
      "9/9 - 176s - loss: 0.0103 - val_loss: 0.0103 - 176s/epoch - 20s/step\n",
      "Epoch 336/350\n",
      "9/9 - 174s - loss: 0.0103 - val_loss: 0.0104 - 174s/epoch - 19s/step\n",
      "Epoch 337/350\n",
      "9/9 - 177s - loss: 0.0103 - val_loss: 0.0103 - 177s/epoch - 20s/step\n",
      "Epoch 338/350\n",
      "9/9 - 177s - loss: 0.0103 - val_loss: 0.0104 - 177s/epoch - 20s/step\n",
      "Epoch 339/350\n",
      "9/9 - 180s - loss: 0.0103 - val_loss: 0.0103 - 180s/epoch - 20s/step\n",
      "Epoch 340/350\n",
      "9/9 - 174s - loss: 0.0104 - val_loss: 0.0103 - 174s/epoch - 19s/step\n",
      "Epoch 341/350\n",
      "9/9 - 175s - loss: 0.0103 - val_loss: 0.0103 - 175s/epoch - 19s/step\n",
      "Epoch 342/350\n",
      "9/9 - 177s - loss: 0.0103 - val_loss: 0.0103 - 177s/epoch - 20s/step\n",
      "Epoch 343/350\n",
      "9/9 - 179s - loss: 0.0103 - val_loss: 0.0103 - 179s/epoch - 20s/step\n",
      "Epoch 344/350\n",
      "9/9 - 177s - loss: 0.0103 - val_loss: 0.0103 - 177s/epoch - 20s/step\n",
      "Epoch 345/350\n",
      "9/9 - 180s - loss: 0.0104 - val_loss: 0.0103 - 180s/epoch - 20s/step\n",
      "Epoch 346/350\n",
      "9/9 - 176s - loss: 0.0103 - val_loss: 0.0103 - 176s/epoch - 20s/step\n",
      "Epoch 347/350\n",
      "9/9 - 176s - loss: 0.0103 - val_loss: 0.0103 - 176s/epoch - 20s/step\n",
      "Epoch 348/350\n",
      "9/9 - 178s - loss: 0.0103 - val_loss: 0.0103 - 178s/epoch - 20s/step\n",
      "Epoch 349/350\n",
      "9/9 - 180s - loss: 0.0103 - val_loss: 0.0103 - 180s/epoch - 20s/step\n",
      "Epoch 350/350\n",
      "9/9 - 198s - loss: 0.0103 - val_loss: 0.0103 - 198s/epoch - 22s/step\n"
     ]
    }
   ],
   "source": [
    "ann_fit_hist = autoencoder.fit(df_data_only_inverted, df_data_only_inverted,\n",
    "                                       epochs=n_epoch,\n",
    "                                       callbacks=[checkpoint],\n",
    "                                       shuffle=True,\n",
    "                                       batch_size=40000,\n",
    "                                       validation_split=0.10,\n",
    "                                       verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_combined = np.vstack((ann_fit_hist.history['loss'], ann_fit_hist.history['val_loss'])).T\n",
    "np.savetxt('ann_network_loss.txt', loss_combined)\n",
    "i_best = np.argmin(ann_fit_hist.history['val_loss'])\n",
    "plt.plot(ann_fit_hist.history['loss'], label='Train')\n",
    "plt.plot(ann_fit_hist.history['val_loss'], label='Validation')\n",
    "plt.axvline(np.arange(n_epoch)[i_best], ls='--', color='black', alpha=0.5)\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss value')\n",
    "plt.ylim(np.nanmin(loss_combined)*0.95, np.nanpercentile(loss_combined, 99))\n",
    "plt.xlim(-1, n_epoch)\n",
    "plt.grid(ls='--', alpha=0.2, color='black')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('ann_network_loss_3.png', dpi=250)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_model_file = 'model_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "Restoring epoch 10 with the loss (0.0126).\n",
      "Saving selected model weights\n",
      "----------------------------------------------------------------\n",
      "Restoring epoch 25 with the loss (0.0126).\n",
      "Saving selected model weights\n",
      "----------------------------------------------------------------\n",
      "Restoring epoch 50 with the loss (0.0112).\n",
      "Saving selected model weights\n",
      "----------------------------------------------------------------\n",
      "Restoring epoch 100 with the loss (0.0110).\n",
      "Saving selected model weights\n",
      "----------------------------------------------------------------\n",
      "Restoring epoch 150 with the loss (0.0112).\n",
      "Saving selected model weights\n",
      "----------------------------------------------------------------\n",
      "Restoring epoch 200 with the loss (0.0107).\n",
      "Saving selected model weights\n",
      "----------------------------------------------------------------\n",
      "Restoring epoch 250 with the loss (0.0104).\n",
      "Saving selected model weights\n",
      "----------------------------------------------------------------\n",
      "Restoring epoch 300 with the loss (0.0104).\n",
      "Saving selected model weights\n"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "        # recover weights of the selected model and compute predictions\n",
    "for i_best in [10, 25, 50, 100, 150, 200, 250, 300]:\n",
    "\n",
    "    h5_weight_files = glob('/data/praveen/autoencoder-run-3/'+'ann_model_run_{:03.0f}-*-*.h5'.format(i_best))\n",
    "\n",
    "    if len(h5_weight_files) == 1:\n",
    "        print('----------------------------------------------------------------')\n",
    "        print('Restoring epoch {:.0f} with the loss ({:.4f}).'.format(i_best, ann_fit_hist.history['val_loss'][i_best-1]))\n",
    "        autoencoder.load_weights(h5_weight_files[0], by_name=True)\n",
    "\n",
    "        sub_dir = 'epoch_{:03.0f}'.format(i_best)\n",
    "        os.system('mkdir ' + sub_dir)\n",
    "        os.chdir(sub_dir)\n",
    "\n",
    "        print('Saving selected model weights')\n",
    "        autoencoder.save_weights(out_model_file)\n",
    "\n",
    "        #print('Predicting values')\n",
    "        #processed_data_all = autoencoder.predict(df_data_only_inverted, verbose=2, batch_size=20)\n",
    "\n",
    "        #plot_sample_spectra()\n",
    "\n",
    "        #print('')\n",
    "        #os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dr3 = pd.read_csv(\"/data/praveen/results/dr3_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sobject_id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>4449</th>\n",
       "      <th>4450</th>\n",
       "      <th>4451</th>\n",
       "      <th>4452</th>\n",
       "      <th>4453</th>\n",
       "      <th>4454</th>\n",
       "      <th>4455</th>\n",
       "      <th>4456</th>\n",
       "      <th>4457</th>\n",
       "      <th>4458</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131116000501002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131116000501004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131116000501005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131116000501006</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131116000501007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sobject_id    0    1    2    3    4    5    6    7    8  ...  4449  \\\n",
       "0  131116000501002  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "1  131116000501004  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "2  131116000501005  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "3  131116000501006  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "4  131116000501007  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  ...   1.0   \n",
       "\n",
       "   4450  4451  4452  4453  4454  4455  4456  4457  4458  \n",
       "0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "1   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "2   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "3   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "4   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0   1.0  \n",
       "\n",
       "[5 rows x 4460 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dr3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19871/1450910931.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  df_dr3_data_only = df_dr3.drop([\"sobject_id\"],1)\n"
     ]
    }
   ],
   "source": [
    "df_dr3_data_only = df_dr3.drop([\"sobject_id\"],1)\n",
    "df_dr3_data_only.head()\n",
    "df_dr3_data_only_inverted = 1 - df_dr3_data_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4449</th>\n",
       "      <th>4450</th>\n",
       "      <th>4451</th>\n",
       "      <th>4452</th>\n",
       "      <th>4453</th>\n",
       "      <th>4454</th>\n",
       "      <th>4455</th>\n",
       "      <th>4456</th>\n",
       "      <th>4457</th>\n",
       "      <th>4458</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  4449  4450  4451  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "   4452  4453  4454  4455  4456  4457  4458  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 4459 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dr3_data_only_inverted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 07:22:47.024456: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 20987407168 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 - 108s - 108s/epoch - 7s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 07:25:10.502746: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 10493703584 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "print('Predicting values')\n",
    "processed_data_all = autoencoder.predict(df_dr3_data_only_inverted, verbose=2, batch_size=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.1997958e-03,  9.8226825e-05,  1.4991947e-03, ...,\n",
       "        -1.7856043e-03,  2.4879040e-04, -7.3287985e-05],\n",
       "       [ 3.7492020e-04,  5.6045060e-04,  2.1412917e-03, ...,\n",
       "        -1.7036146e-03, -3.1532897e-04, -6.9066649e-05],\n",
       "       [ 1.8160930e-03,  1.0974763e-03,  1.4585606e-03, ...,\n",
       "        -1.6279925e-03, -8.0028980e-04,  5.2182085e-04],\n",
       "       ...,\n",
       "       [ 5.9819175e-04,  4.1774567e-04,  1.3771225e-03, ...,\n",
       "        -1.4776291e-03, -8.0229889e-04,  2.2542663e-06],\n",
       "       [ 3.8899994e-04,  7.4241892e-04,  1.5537017e-03, ...,\n",
       "        -1.7032403e-03, -8.3542161e-04,  3.8431445e-04],\n",
       "       [ 3.1395530e-04,  5.5772159e-04,  1.5193019e-03, ...,\n",
       "        -1.4407267e-03, -5.8047520e-04, -3.6799931e-05]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_all = pd.DataFrame(processed_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4449</th>\n",
       "      <th>4450</th>\n",
       "      <th>4451</th>\n",
       "      <th>4452</th>\n",
       "      <th>4453</th>\n",
       "      <th>4454</th>\n",
       "      <th>4455</th>\n",
       "      <th>4456</th>\n",
       "      <th>4457</th>\n",
       "      <th>4458</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>-0.001643</td>\n",
       "      <td>-0.000947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.000805</td>\n",
       "      <td>-0.000936</td>\n",
       "      <td>-0.000488</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.000073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>-0.001789</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>-0.001704</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>-0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>-0.000449</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>-0.001944</td>\n",
       "      <td>-0.000709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>-0.000800</td>\n",
       "      <td>0.000522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>-0.000209</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.000274</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>-0.000165</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>-0.001407</td>\n",
       "      <td>-0.000620</td>\n",
       "      <td>0.000346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>-0.000253</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>-0.000316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000348</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>-0.000520</td>\n",
       "      <td>-0.000462</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>-0.000188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 4459 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.002200  0.000098  0.001499  0.000882 -0.000300  0.000458  0.000638   \n",
       "1  0.000375  0.000560  0.002141 -0.000300  0.000356 -0.000474 -0.000065   \n",
       "2  0.001816  0.001097  0.001459 -0.000360  0.000150 -0.000449 -0.000005   \n",
       "3  0.001243  0.000601  0.001617 -0.000209  0.000440 -0.000274 -0.000085   \n",
       "4  0.000385  0.000506  0.001442 -0.000253  0.000405  0.000023 -0.000049   \n",
       "\n",
       "       7         8         9     ...      4449      4450      4451      4452  \\\n",
       "0  0.001344 -0.001643 -0.000947  ... -0.000540 -0.000805 -0.000936 -0.000488   \n",
       "1  0.000687 -0.001789 -0.000165  ... -0.000501  0.000197 -0.000166  0.000494   \n",
       "2  0.000237 -0.001944 -0.000709  ... -0.000544  0.000376 -0.000768  0.000507   \n",
       "3  0.000156 -0.001582 -0.000190  ... -0.000605  0.000211 -0.000714  0.000798   \n",
       "4  0.000977 -0.001584 -0.000316  ... -0.000348 -0.000122 -0.000900  0.000342   \n",
       "\n",
       "       4453      4454      4455      4456      4457      4458  \n",
       "0 -0.000110 -0.000435  0.000664 -0.001786  0.000249 -0.000073  \n",
       "1  0.000022 -0.000314  0.000552 -0.001704 -0.000315 -0.000069  \n",
       "2 -0.000511 -0.000685  0.000833 -0.001628 -0.000800  0.000522  \n",
       "3 -0.000165 -0.000473  0.000779 -0.001407 -0.000620  0.000346  \n",
       "4 -0.000520 -0.000462  0.000448 -0.001291 -0.000874 -0.000188  \n",
       "\n",
       "[5 rows x 4459 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_all.to_csv(\"/data/praveen/results/dr3_full_predicted_inverted_3.csv\",index=None)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3aa1867c408c14afe351cfd5d1be181646832c7964023d6477fd09a3c85411b7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
