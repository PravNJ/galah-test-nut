{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [16,9]\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dr3_all = pd.read_csv(\"/data/praveen/results/dr3_normal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dr3_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dr3_all[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data_only = df_dr3_all.drop([\"sobject_id\",\"label\"],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_only_inverted = 1 - df_data_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import backend as K\n",
    "#from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = None  # PReLU if set to None\n",
    "dropout_rate = 0  # from 0 to 1\n",
    "n_l_e = 5\n",
    "n_epoch = 350\n",
    "decoded_layer_name = 'encoded'\n",
    "n_wvl = 4459\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# compute number of nodes in every connected layer\n",
    "n_l_1 = int(n_wvl * 0.75)\n",
    "n_l_2 = int(n_wvl * 0.50)\n",
    "n_l_3 = 0  # int(n_wvl * 0.40)\n",
    "n_l_4 = 0  # int(n_wvl * 0.20)\n",
    "n_l_5 = int(n_wvl * 0.25)\n",
    "n_l_6 = int(n_wvl * 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Sequential()\n",
    "\n",
    "if n_l_1 > 0:\n",
    "    autoencoder.add(Dense(n_l_1, input_shape=(n_wvl,), activation=activation, name='E_1'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_1'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_1'))\n",
    "\n",
    "if n_l_2 > 0:\n",
    "    autoencoder.add(Dense(n_l_2, activation=activation, name='E_2'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_2'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_2'))\n",
    "\n",
    "if n_l_3 > 0:\n",
    "    autoencoder.add(Dense(n_l_3, activation=activation, name='E_3'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_3'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_3'))\n",
    "\n",
    "if n_l_4 > 0:\n",
    "    autoencoder.add(Dense(n_l_4, activation=activation, name='E_4'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_4'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_4'))\n",
    "\n",
    "if n_l_5 > 0:\n",
    "    autoencoder.add(Dense(n_l_5, activation=activation, name='E_5'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_5'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_5'))\n",
    "\n",
    "if n_l_6 > 0:\n",
    "    autoencoder.add(Dense(n_l_6, activation=activation, name='E_6'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_6'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_6'))\n",
    "\n",
    "autoencoder.add(Dense(n_l_e, activation=activation, name=decoded_layer_name))\n",
    "if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_7'))\n",
    "\n",
    "if n_l_6 > 0:\n",
    "    autoencoder.add(Dense(n_l_6, activation=activation, name='D_1'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_8'))\n",
    "    if activation is None:\n",
    "            autoencoder.add(PReLU(name='PR_8'))\n",
    "\n",
    "if n_l_5 > 0:\n",
    "    autoencoder.add(Dense(n_l_5, activation=activation, name='D_2'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_9'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_9'))\n",
    "\n",
    "if n_l_4 > 0:\n",
    "    autoencoder.add(Dense(n_l_4, activation=activation, name='D_3'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_10'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_10'))\n",
    "\n",
    "if n_l_3 > 0:\n",
    "    autoencoder.add(Dense(n_l_3, activation=activation, name='D_4'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_11'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_11'))\n",
    "\n",
    "if n_l_2 > 0:\n",
    "    autoencoder.add(Dense(n_l_2, activation=activation, name='D_5'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_12'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_12'))\n",
    "\n",
    "if n_l_1 > 0:\n",
    "    autoencoder.add(Dense(n_l_1, activation=activation, name='D_6'))\n",
    "    if dropout_rate > 0:\n",
    "        autoencoder.add(Dropout(dropout_rate, name='DO_13'))\n",
    "    if activation is None:\n",
    "        autoencoder.add(PReLU(name='PR_13'))\n",
    "\n",
    "autoencoder.add(Dense(n_wvl, activation='linear', name='recreated'))\n",
    "autoencoder.summary()\n",
    "\n",
    "# Visualize network architecture and save the visualization as a file\n",
    "#plot_model(autoencoder, show_layer_names=True, show_shapes=True, to_file='ann_network_structure_a.pdf')\n",
    "#plot_model(autoencoder, show_layer_names=True, show_shapes=True, to_file='ann_network_structure_a.png', dpi=300)\n",
    "\n",
    "# model file handling\n",
    "out_model_file = 'model_weights.h5'\n",
    "\n",
    "if os.path.isfile(out_model_file):\n",
    "    autoencoder.load_weights(out_model_file, by_name=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer=optimizer, loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('/data/praveen/autoencoder-run-2'+'ann_model_run_{epoch:03d}-{loss:.4f}-{val_loss:.4f}.h5',\n",
    "                                     monitor='val_loss', verbose=0, save_best_only=False,\n",
    "                                     save_weights_only=True, mode='auto', period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-11 22:32:00.843361: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18664660560 exceeds 10% of free system memory.\n",
      "2022-04-11 22:35:39.758669: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 18664660560 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "14/14 - 334s - loss: 0.0356 - val_loss: 0.0297 - 334s/epoch - 24s/step\n",
      "Epoch 2/350\n",
      "14/14 - 266s - loss: 0.0280 - val_loss: 0.0268 - 266s/epoch - 19s/step\n",
      "Epoch 3/350\n",
      "14/14 - 289s - loss: 0.0260 - val_loss: 0.0249 - 289s/epoch - 21s/step\n",
      "Epoch 4/350\n",
      "14/14 - 294s - loss: 0.0251 - val_loss: 0.0225 - 294s/epoch - 21s/step\n",
      "Epoch 5/350\n",
      "14/14 - 292s - loss: 0.0208 - val_loss: 0.0197 - 292s/epoch - 21s/step\n",
      "Epoch 6/350\n",
      "14/14 - 288s - loss: 0.0190 - val_loss: 0.0185 - 288s/epoch - 21s/step\n",
      "Epoch 7/350\n",
      "14/14 - 283s - loss: 0.0183 - val_loss: 0.0182 - 283s/epoch - 20s/step\n",
      "Epoch 8/350\n",
      "14/14 - 286s - loss: 0.0180 - val_loss: 0.0179 - 286s/epoch - 20s/step\n",
      "Epoch 9/350\n",
      "14/14 - 288s - loss: 0.0178 - val_loss: 0.0180 - 288s/epoch - 21s/step\n",
      "Epoch 10/350\n",
      "14/14 - 286s - loss: 0.0178 - val_loss: 0.0178 - 286s/epoch - 20s/step\n",
      "Epoch 11/350\n",
      "14/14 - 286s - loss: 0.0177 - val_loss: 0.0178 - 286s/epoch - 20s/step\n",
      "Epoch 12/350\n",
      "14/14 - 288s - loss: 0.0176 - val_loss: 0.0177 - 288s/epoch - 21s/step\n",
      "Epoch 13/350\n",
      "14/14 - 282s - loss: 0.0176 - val_loss: 0.0177 - 282s/epoch - 20s/step\n",
      "Epoch 14/350\n",
      "14/14 - 281s - loss: 0.0176 - val_loss: 0.0177 - 281s/epoch - 20s/step\n",
      "Epoch 15/350\n",
      "14/14 - 279s - loss: 0.0176 - val_loss: 0.0177 - 279s/epoch - 20s/step\n",
      "Epoch 16/350\n",
      "14/14 - 277s - loss: 0.0176 - val_loss: 0.0177 - 277s/epoch - 20s/step\n",
      "Epoch 17/350\n",
      "14/14 - 282s - loss: 0.0176 - val_loss: 0.0177 - 282s/epoch - 20s/step\n",
      "Epoch 18/350\n",
      "14/14 - 276s - loss: 0.0176 - val_loss: 0.0177 - 276s/epoch - 20s/step\n",
      "Epoch 19/350\n",
      "14/14 - 272s - loss: 0.0176 - val_loss: 0.0177 - 272s/epoch - 19s/step\n",
      "Epoch 20/350\n",
      "14/14 - 269s - loss: 0.0175 - val_loss: 0.0177 - 269s/epoch - 19s/step\n",
      "Epoch 21/350\n",
      "14/14 - 278s - loss: 0.0176 - val_loss: 0.0176 - 278s/epoch - 20s/step\n",
      "Epoch 22/350\n",
      "14/14 - 282s - loss: 0.0175 - val_loss: 0.0177 - 282s/epoch - 20s/step\n",
      "Epoch 23/350\n",
      "14/14 - 288s - loss: 0.0175 - val_loss: 0.0176 - 288s/epoch - 21s/step\n",
      "Epoch 24/350\n",
      "14/14 - 291s - loss: 0.0176 - val_loss: 0.0177 - 291s/epoch - 21s/step\n",
      "Epoch 25/350\n",
      "14/14 - 290s - loss: 0.0176 - val_loss: 0.0178 - 290s/epoch - 21s/step\n",
      "Epoch 26/350\n",
      "14/14 - 284s - loss: 0.0176 - val_loss: 0.0177 - 284s/epoch - 20s/step\n",
      "Epoch 27/350\n",
      "14/14 - 279s - loss: 0.0176 - val_loss: 0.0177 - 279s/epoch - 20s/step\n",
      "Epoch 28/350\n",
      "14/14 - 291s - loss: 0.0175 - val_loss: 0.0177 - 291s/epoch - 21s/step\n",
      "Epoch 29/350\n",
      "14/14 - 292s - loss: 0.0176 - val_loss: 0.0173 - 292s/epoch - 21s/step\n",
      "Epoch 30/350\n",
      "14/14 - 290s - loss: 0.0177 - val_loss: 0.0183 - 290s/epoch - 21s/step\n",
      "Epoch 31/350\n",
      "14/14 - 291s - loss: 0.0176 - val_loss: 0.0171 - 291s/epoch - 21s/step\n",
      "Epoch 32/350\n",
      "14/14 - 283s - loss: 0.0168 - val_loss: 0.0167 - 283s/epoch - 20s/step\n",
      "Epoch 33/350\n",
      "14/14 - 280s - loss: 0.0172 - val_loss: 0.0169 - 280s/epoch - 20s/step\n",
      "Epoch 34/350\n",
      "14/14 - 281s - loss: 0.0165 - val_loss: 0.0162 - 281s/epoch - 20s/step\n",
      "Epoch 35/350\n",
      "14/14 - 282s - loss: 0.0160 - val_loss: 0.0159 - 282s/epoch - 20s/step\n",
      "Epoch 36/350\n",
      "14/14 - 280s - loss: 0.0159 - val_loss: 0.0161 - 280s/epoch - 20s/step\n",
      "Epoch 37/350\n",
      "14/14 - 284s - loss: 0.0158 - val_loss: 0.0158 - 284s/epoch - 20s/step\n",
      "Epoch 38/350\n",
      "14/14 - 286s - loss: 0.0157 - val_loss: 0.0157 - 286s/epoch - 20s/step\n",
      "Epoch 39/350\n",
      "14/14 - 285s - loss: 0.0157 - val_loss: 0.0157 - 285s/epoch - 20s/step\n",
      "Epoch 40/350\n",
      "14/14 - 287s - loss: 0.0156 - val_loss: 0.0157 - 287s/epoch - 20s/step\n",
      "Epoch 41/350\n",
      "14/14 - 280s - loss: 0.0157 - val_loss: 0.0156 - 280s/epoch - 20s/step\n",
      "Epoch 42/350\n",
      "14/14 - 282s - loss: 0.0156 - val_loss: 0.0157 - 282s/epoch - 20s/step\n",
      "Epoch 43/350\n",
      "14/14 - 285s - loss: 0.0156 - val_loss: 0.0158 - 285s/epoch - 20s/step\n",
      "Epoch 44/350\n",
      "14/14 - 284s - loss: 0.0156 - val_loss: 0.0157 - 284s/epoch - 20s/step\n",
      "Epoch 45/350\n",
      "14/14 - 285s - loss: 0.0156 - val_loss: 0.0156 - 285s/epoch - 20s/step\n",
      "Epoch 46/350\n",
      "14/14 - 279s - loss: 0.0155 - val_loss: 0.0156 - 279s/epoch - 20s/step\n",
      "Epoch 47/350\n",
      "14/14 - 282s - loss: 0.0155 - val_loss: 0.0155 - 282s/epoch - 20s/step\n",
      "Epoch 48/350\n",
      "14/14 - 281s - loss: 0.0155 - val_loss: 0.0157 - 281s/epoch - 20s/step\n",
      "Epoch 49/350\n",
      "14/14 - 280s - loss: 0.0157 - val_loss: 0.0155 - 280s/epoch - 20s/step\n",
      "Epoch 50/350\n",
      "14/14 - 285s - loss: 0.0155 - val_loss: 0.0155 - 285s/epoch - 20s/step\n",
      "Epoch 51/350\n",
      "14/14 - 279s - loss: 0.0155 - val_loss: 0.0155 - 279s/epoch - 20s/step\n",
      "Epoch 52/350\n",
      "14/14 - 284s - loss: 0.0155 - val_loss: 0.0155 - 284s/epoch - 20s/step\n",
      "Epoch 53/350\n",
      "14/14 - 282s - loss: 0.0154 - val_loss: 0.0155 - 282s/epoch - 20s/step\n",
      "Epoch 54/350\n",
      "14/14 - 285s - loss: 0.0155 - val_loss: 0.0155 - 285s/epoch - 20s/step\n",
      "Epoch 55/350\n",
      "14/14 - 281s - loss: 0.0155 - val_loss: 0.0155 - 281s/epoch - 20s/step\n",
      "Epoch 56/350\n",
      "14/14 - 282s - loss: 0.0155 - val_loss: 0.0155 - 282s/epoch - 20s/step\n",
      "Epoch 57/350\n",
      "14/14 - 283s - loss: 0.0154 - val_loss: 0.0155 - 283s/epoch - 20s/step\n",
      "Epoch 58/350\n",
      "14/14 - 285s - loss: 0.0154 - val_loss: 0.0155 - 285s/epoch - 20s/step\n",
      "Epoch 59/350\n",
      "14/14 - 287s - loss: 0.0154 - val_loss: 0.0154 - 287s/epoch - 20s/step\n",
      "Epoch 60/350\n",
      "14/14 - 282s - loss: 0.0155 - val_loss: 0.0155 - 282s/epoch - 20s/step\n",
      "Epoch 61/350\n",
      "14/14 - 285s - loss: 0.0154 - val_loss: 0.0155 - 285s/epoch - 20s/step\n",
      "Epoch 62/350\n",
      "14/14 - 283s - loss: 0.0154 - val_loss: 0.0154 - 283s/epoch - 20s/step\n",
      "Epoch 63/350\n",
      "14/14 - 283s - loss: 0.0154 - val_loss: 0.0156 - 283s/epoch - 20s/step\n",
      "Epoch 64/350\n",
      "14/14 - 281s - loss: 0.0154 - val_loss: 0.0154 - 281s/epoch - 20s/step\n",
      "Epoch 65/350\n",
      "14/14 - 284s - loss: 0.0154 - val_loss: 0.0155 - 284s/epoch - 20s/step\n",
      "Epoch 66/350\n",
      "14/14 - 281s - loss: 0.0154 - val_loss: 0.0154 - 281s/epoch - 20s/step\n",
      "Epoch 67/350\n",
      "14/14 - 284s - loss: 0.0153 - val_loss: 0.0155 - 284s/epoch - 20s/step\n",
      "Epoch 68/350\n",
      "14/14 - 284s - loss: 0.0153 - val_loss: 0.0154 - 284s/epoch - 20s/step\n",
      "Epoch 69/350\n",
      "14/14 - 278s - loss: 0.0154 - val_loss: 0.0154 - 278s/epoch - 20s/step\n",
      "Epoch 70/350\n",
      "14/14 - 281s - loss: 0.0153 - val_loss: 0.0154 - 281s/epoch - 20s/step\n",
      "Epoch 71/350\n",
      "14/14 - 279s - loss: 0.0153 - val_loss: 0.0154 - 279s/epoch - 20s/step\n",
      "Epoch 72/350\n",
      "14/14 - 281s - loss: 0.0153 - val_loss: 0.0154 - 281s/epoch - 20s/step\n",
      "Epoch 73/350\n",
      "14/14 - 282s - loss: 0.0153 - val_loss: 0.0154 - 282s/epoch - 20s/step\n",
      "Epoch 74/350\n",
      "14/14 - 282s - loss: 0.0154 - val_loss: 0.0154 - 282s/epoch - 20s/step\n",
      "Epoch 75/350\n",
      "14/14 - 278s - loss: 0.0153 - val_loss: 0.0153 - 278s/epoch - 20s/step\n",
      "Epoch 76/350\n",
      "14/14 - 278s - loss: 0.0153 - val_loss: 0.0153 - 278s/epoch - 20s/step\n",
      "Epoch 77/350\n",
      "14/14 - 282s - loss: 0.0153 - val_loss: 0.0154 - 282s/epoch - 20s/step\n",
      "Epoch 78/350\n",
      "14/14 - 278s - loss: 0.0153 - val_loss: 0.0154 - 278s/epoch - 20s/step\n",
      "Epoch 79/350\n",
      "14/14 - 282s - loss: 0.0153 - val_loss: 0.0154 - 282s/epoch - 20s/step\n",
      "Epoch 80/350\n",
      "14/14 - 275s - loss: 0.0153 - val_loss: 0.0154 - 275s/epoch - 20s/step\n",
      "Epoch 81/350\n",
      "14/14 - 276s - loss: 0.0153 - val_loss: 0.0154 - 276s/epoch - 20s/step\n",
      "Epoch 82/350\n",
      "14/14 - 285s - loss: 0.0153 - val_loss: 0.0154 - 285s/epoch - 20s/step\n",
      "Epoch 83/350\n",
      "14/14 - 284s - loss: 0.0153 - val_loss: 0.0154 - 284s/epoch - 20s/step\n",
      "Epoch 84/350\n",
      "14/14 - 285s - loss: 0.0153 - val_loss: 0.0154 - 285s/epoch - 20s/step\n",
      "Epoch 85/350\n",
      "14/14 - 278s - loss: 0.0153 - val_loss: 0.0154 - 278s/epoch - 20s/step\n",
      "Epoch 86/350\n",
      "14/14 - 280s - loss: 0.0154 - val_loss: 0.0154 - 280s/epoch - 20s/step\n",
      "Epoch 87/350\n",
      "14/14 - 279s - loss: 0.0153 - val_loss: 0.0153 - 279s/epoch - 20s/step\n",
      "Epoch 88/350\n",
      "14/14 - 281s - loss: 0.0153 - val_loss: 0.0153 - 281s/epoch - 20s/step\n",
      "Epoch 89/350\n",
      "14/14 - 277s - loss: 0.0153 - val_loss: 0.0153 - 277s/epoch - 20s/step\n",
      "Epoch 90/350\n",
      "14/14 - 278s - loss: 0.0153 - val_loss: 0.0154 - 278s/epoch - 20s/step\n",
      "Epoch 91/350\n",
      "14/14 - 284s - loss: 0.0153 - val_loss: 0.0153 - 284s/epoch - 20s/step\n",
      "Epoch 92/350\n",
      "14/14 - 276s - loss: 0.0153 - val_loss: 0.0154 - 276s/epoch - 20s/step\n",
      "Epoch 93/350\n",
      "14/14 - 279s - loss: 0.0153 - val_loss: 0.0153 - 279s/epoch - 20s/step\n",
      "Epoch 94/350\n",
      "14/14 - 279s - loss: 0.0153 - val_loss: 0.0153 - 279s/epoch - 20s/step\n",
      "Epoch 95/350\n",
      "14/14 - 279s - loss: 0.0153 - val_loss: 0.0153 - 279s/epoch - 20s/step\n",
      "Epoch 96/350\n",
      "14/14 - 280s - loss: 0.0152 - val_loss: 0.0153 - 280s/epoch - 20s/step\n",
      "Epoch 97/350\n",
      "14/14 - 280s - loss: 0.0153 - val_loss: 0.0154 - 280s/epoch - 20s/step\n",
      "Epoch 98/350\n",
      "14/14 - 281s - loss: 0.0152 - val_loss: 0.0153 - 281s/epoch - 20s/step\n",
      "Epoch 99/350\n",
      "14/14 - 276s - loss: 0.0152 - val_loss: 0.0152 - 276s/epoch - 20s/step\n",
      "Epoch 100/350\n",
      "14/14 - 279s - loss: 0.0152 - val_loss: 0.0152 - 279s/epoch - 20s/step\n",
      "Epoch 101/350\n",
      "14/14 - 279s - loss: 0.0152 - val_loss: 0.0153 - 279s/epoch - 20s/step\n",
      "Epoch 102/350\n",
      "14/14 - 286s - loss: 0.0152 - val_loss: 0.0152 - 286s/epoch - 20s/step\n",
      "Epoch 103/350\n",
      "14/14 - 280s - loss: 0.0152 - val_loss: 0.0152 - 280s/epoch - 20s/step\n",
      "Epoch 104/350\n",
      "14/14 - 278s - loss: 0.0152 - val_loss: 0.0152 - 278s/epoch - 20s/step\n",
      "Epoch 105/350\n",
      "14/14 - 273s - loss: 0.0152 - val_loss: 0.0152 - 273s/epoch - 19s/step\n",
      "Epoch 106/350\n",
      "14/14 - 273s - loss: 0.0151 - val_loss: 0.0151 - 273s/epoch - 20s/step\n",
      "Epoch 107/350\n",
      "14/14 - 273s - loss: 0.0152 - val_loss: 0.0151 - 273s/epoch - 19s/step\n",
      "Epoch 108/350\n",
      "14/14 - 279s - loss: 0.0151 - val_loss: 0.0151 - 279s/epoch - 20s/step\n",
      "Epoch 109/350\n",
      "14/14 - 277s - loss: 0.0151 - val_loss: 0.0151 - 277s/epoch - 20s/step\n",
      "Epoch 110/350\n",
      "14/14 - 281s - loss: 0.0151 - val_loss: 0.0152 - 281s/epoch - 20s/step\n",
      "Epoch 111/350\n",
      "14/14 - 272s - loss: 0.0151 - val_loss: 0.0151 - 272s/epoch - 19s/step\n",
      "Epoch 112/350\n",
      "14/14 - 277s - loss: 0.0150 - val_loss: 0.0152 - 277s/epoch - 20s/step\n",
      "Epoch 113/350\n",
      "14/14 - 275s - loss: 0.0151 - val_loss: 0.0150 - 275s/epoch - 20s/step\n",
      "Epoch 114/350\n",
      "14/14 - 279s - loss: 0.0150 - val_loss: 0.0150 - 279s/epoch - 20s/step\n",
      "Epoch 115/350\n",
      "14/14 - 279s - loss: 0.0150 - val_loss: 0.0152 - 279s/epoch - 20s/step\n",
      "Epoch 116/350\n",
      "14/14 - 273s - loss: 0.0150 - val_loss: 0.0151 - 273s/epoch - 20s/step\n",
      "Epoch 117/350\n",
      "14/14 - 275s - loss: 0.0150 - val_loss: 0.0149 - 275s/epoch - 20s/step\n",
      "Epoch 118/350\n",
      "14/14 - 275s - loss: 0.0149 - val_loss: 0.0150 - 275s/epoch - 20s/step\n",
      "Epoch 119/350\n",
      "14/14 - 276s - loss: 0.0149 - val_loss: 0.0149 - 276s/epoch - 20s/step\n",
      "Epoch 120/350\n",
      "14/14 - 285s - loss: 0.0149 - val_loss: 0.0149 - 285s/epoch - 20s/step\n",
      "Epoch 121/350\n",
      "14/14 - 286s - loss: 0.0149 - val_loss: 0.0149 - 286s/epoch - 20s/step\n",
      "Epoch 122/350\n",
      "14/14 - 279s - loss: 0.0149 - val_loss: 0.0149 - 279s/epoch - 20s/step\n",
      "Epoch 123/350\n",
      "14/14 - 278s - loss: 0.0149 - val_loss: 0.0149 - 278s/epoch - 20s/step\n",
      "Epoch 124/350\n",
      "14/14 - 280s - loss: 0.0150 - val_loss: 0.0151 - 280s/epoch - 20s/step\n",
      "Epoch 125/350\n",
      "14/14 - 279s - loss: 0.0149 - val_loss: 0.0148 - 279s/epoch - 20s/step\n",
      "Epoch 126/350\n",
      "14/14 - 269s - loss: 0.0148 - val_loss: 0.0152 - 269s/epoch - 19s/step\n",
      "Epoch 127/350\n",
      "14/14 - 267s - loss: 0.0149 - val_loss: 0.0148 - 267s/epoch - 19s/step\n",
      "Epoch 128/350\n",
      "14/14 - 266s - loss: 0.0148 - val_loss: 0.0150 - 266s/epoch - 19s/step\n",
      "Epoch 129/350\n",
      "14/14 - 275s - loss: 0.0148 - val_loss: 0.0148 - 275s/epoch - 20s/step\n",
      "Epoch 130/350\n",
      "14/14 - 272s - loss: 0.0148 - val_loss: 0.0148 - 272s/epoch - 19s/step\n",
      "Epoch 131/350\n",
      "14/14 - 274s - loss: 0.0148 - val_loss: 0.0148 - 274s/epoch - 20s/step\n",
      "Epoch 132/350\n",
      "14/14 - 283s - loss: 0.0147 - val_loss: 0.0148 - 283s/epoch - 20s/step\n",
      "Epoch 133/350\n",
      "14/14 - 285s - loss: 0.0147 - val_loss: 0.0147 - 285s/epoch - 20s/step\n",
      "Epoch 134/350\n",
      "14/14 - 280s - loss: 0.0147 - val_loss: 0.0148 - 280s/epoch - 20s/step\n",
      "Epoch 135/350\n",
      "14/14 - 287s - loss: 0.0147 - val_loss: 0.0147 - 287s/epoch - 20s/step\n",
      "Epoch 136/350\n",
      "14/14 - 288s - loss: 0.0147 - val_loss: 0.0147 - 288s/epoch - 21s/step\n",
      "Epoch 137/350\n",
      "14/14 - 285s - loss: 0.0147 - val_loss: 0.0149 - 285s/epoch - 20s/step\n",
      "Epoch 138/350\n",
      "14/14 - 285s - loss: 0.0148 - val_loss: 0.0148 - 285s/epoch - 20s/step\n",
      "Epoch 139/350\n",
      "14/14 - 282s - loss: 0.0147 - val_loss: 0.0149 - 282s/epoch - 20s/step\n",
      "Epoch 140/350\n",
      "14/14 - 289s - loss: 0.0147 - val_loss: 0.0147 - 289s/epoch - 21s/step\n",
      "Epoch 141/350\n",
      "14/14 - 288s - loss: 0.0146 - val_loss: 0.0146 - 288s/epoch - 21s/step\n",
      "Epoch 142/350\n",
      "14/14 - 280s - loss: 0.0146 - val_loss: 0.0147 - 280s/epoch - 20s/step\n",
      "Epoch 143/350\n",
      "14/14 - 285s - loss: 0.0146 - val_loss: 0.0147 - 285s/epoch - 20s/step\n",
      "Epoch 144/350\n",
      "14/14 - 277s - loss: 0.0146 - val_loss: 0.0146 - 277s/epoch - 20s/step\n",
      "Epoch 145/350\n",
      "14/14 - 283s - loss: 0.0146 - val_loss: 0.0147 - 283s/epoch - 20s/step\n",
      "Epoch 146/350\n",
      "14/14 - 285s - loss: 0.0146 - val_loss: 0.0146 - 285s/epoch - 20s/step\n",
      "Epoch 147/350\n",
      "14/14 - 286s - loss: 0.0146 - val_loss: 0.0146 - 286s/epoch - 20s/step\n",
      "Epoch 148/350\n",
      "14/14 - 281s - loss: 0.0146 - val_loss: 0.0147 - 281s/epoch - 20s/step\n",
      "Epoch 149/350\n",
      "14/14 - 286s - loss: 0.0145 - val_loss: 0.0146 - 286s/epoch - 20s/step\n",
      "Epoch 150/350\n",
      "14/14 - 280s - loss: 0.0146 - val_loss: 0.0146 - 280s/epoch - 20s/step\n",
      "Epoch 151/350\n",
      "14/14 - 283s - loss: 0.0145 - val_loss: 0.0145 - 283s/epoch - 20s/step\n",
      "Epoch 152/350\n",
      "14/14 - 281s - loss: 0.0145 - val_loss: 0.0146 - 281s/epoch - 20s/step\n",
      "Epoch 153/350\n",
      "14/14 - 279s - loss: 0.0145 - val_loss: 0.0146 - 279s/epoch - 20s/step\n",
      "Epoch 154/350\n",
      "14/14 - 280s - loss: 0.0145 - val_loss: 0.0146 - 280s/epoch - 20s/step\n",
      "Epoch 155/350\n",
      "14/14 - 277s - loss: 0.0146 - val_loss: 0.0145 - 277s/epoch - 20s/step\n",
      "Epoch 156/350\n",
      "14/14 - 281s - loss: 0.0146 - val_loss: 0.0147 - 281s/epoch - 20s/step\n",
      "Epoch 157/350\n",
      "14/14 - 283s - loss: 0.0145 - val_loss: 0.0146 - 283s/epoch - 20s/step\n",
      "Epoch 158/350\n",
      "14/14 - 280s - loss: 0.0145 - val_loss: 0.0146 - 280s/epoch - 20s/step\n",
      "Epoch 159/350\n",
      "14/14 - 278s - loss: 0.0145 - val_loss: 0.0145 - 278s/epoch - 20s/step\n",
      "Epoch 160/350\n",
      "14/14 - 281s - loss: 0.0145 - val_loss: 0.0146 - 281s/epoch - 20s/step\n",
      "Epoch 161/350\n",
      "14/14 - 281s - loss: 0.0146 - val_loss: 0.0146 - 281s/epoch - 20s/step\n",
      "Epoch 162/350\n",
      "14/14 - 279s - loss: 0.0145 - val_loss: 0.0146 - 279s/epoch - 20s/step\n",
      "Epoch 163/350\n",
      "14/14 - 281s - loss: 0.0145 - val_loss: 0.0145 - 281s/epoch - 20s/step\n",
      "Epoch 164/350\n",
      "14/14 - 283s - loss: 0.0145 - val_loss: 0.0145 - 283s/epoch - 20s/step\n",
      "Epoch 165/350\n",
      "14/14 - 277s - loss: 0.0145 - val_loss: 0.0145 - 277s/epoch - 20s/step\n",
      "Epoch 166/350\n",
      "14/14 - 285s - loss: 0.0145 - val_loss: 0.0145 - 285s/epoch - 20s/step\n",
      "Epoch 167/350\n",
      "14/14 - 280s - loss: 0.0145 - val_loss: 0.0145 - 280s/epoch - 20s/step\n",
      "Epoch 168/350\n",
      "14/14 - 278s - loss: 0.0144 - val_loss: 0.0145 - 278s/epoch - 20s/step\n",
      "Epoch 169/350\n",
      "14/14 - 282s - loss: 0.0145 - val_loss: 0.0145 - 282s/epoch - 20s/step\n",
      "Epoch 170/350\n",
      "14/14 - 281s - loss: 0.0144 - val_loss: 0.0145 - 281s/epoch - 20s/step\n",
      "Epoch 171/350\n",
      "14/14 - 277s - loss: 0.0144 - val_loss: 0.0145 - 277s/epoch - 20s/step\n",
      "Epoch 172/350\n",
      "14/14 - 282s - loss: 0.0144 - val_loss: 0.0145 - 282s/epoch - 20s/step\n",
      "Epoch 173/350\n",
      "14/14 - 282s - loss: 0.0144 - val_loss: 0.0145 - 282s/epoch - 20s/step\n",
      "Epoch 174/350\n",
      "14/14 - 270s - loss: 0.0144 - val_loss: 0.0146 - 270s/epoch - 19s/step\n",
      "Epoch 175/350\n",
      "14/14 - 277s - loss: 0.0145 - val_loss: 0.0146 - 277s/epoch - 20s/step\n",
      "Epoch 176/350\n",
      "14/14 - 273s - loss: 0.0144 - val_loss: 0.0145 - 273s/epoch - 20s/step\n",
      "Epoch 177/350\n",
      "14/14 - 280s - loss: 0.0144 - val_loss: 0.0146 - 280s/epoch - 20s/step\n",
      "Epoch 178/350\n",
      "14/14 - 283s - loss: 0.0144 - val_loss: 0.0145 - 283s/epoch - 20s/step\n",
      "Epoch 179/350\n",
      "14/14 - 283s - loss: 0.0144 - val_loss: 0.0145 - 283s/epoch - 20s/step\n",
      "Epoch 180/350\n",
      "14/14 - 281s - loss: 0.0144 - val_loss: 0.0145 - 281s/epoch - 20s/step\n",
      "Epoch 181/350\n",
      "14/14 - 281s - loss: 0.0144 - val_loss: 0.0145 - 281s/epoch - 20s/step\n",
      "Epoch 182/350\n",
      "14/14 - 279s - loss: 0.0144 - val_loss: 0.0145 - 279s/epoch - 20s/step\n",
      "Epoch 183/350\n",
      "14/14 - 282s - loss: 0.0144 - val_loss: 0.0145 - 282s/epoch - 20s/step\n",
      "Epoch 184/350\n",
      "14/14 - 281s - loss: 0.0144 - val_loss: 0.0145 - 281s/epoch - 20s/step\n",
      "Epoch 185/350\n",
      "14/14 - 282s - loss: 0.0144 - val_loss: 0.0145 - 282s/epoch - 20s/step\n",
      "Epoch 186/350\n",
      "14/14 - 278s - loss: 0.0144 - val_loss: 0.0145 - 278s/epoch - 20s/step\n",
      "Epoch 187/350\n",
      "14/14 - 278s - loss: 0.0144 - val_loss: 0.0145 - 278s/epoch - 20s/step\n",
      "Epoch 188/350\n",
      "14/14 - 283s - loss: 0.0144 - val_loss: 0.0145 - 283s/epoch - 20s/step\n",
      "Epoch 189/350\n",
      "14/14 - 277s - loss: 0.0144 - val_loss: 0.0145 - 277s/epoch - 20s/step\n",
      "Epoch 190/350\n",
      "14/14 - 279s - loss: 0.0144 - val_loss: 0.0145 - 279s/epoch - 20s/step\n",
      "Epoch 191/350\n",
      "14/14 - 275s - loss: 0.0144 - val_loss: 0.0145 - 275s/epoch - 20s/step\n",
      "Epoch 192/350\n",
      "14/14 - 278s - loss: 0.0144 - val_loss: 0.0145 - 278s/epoch - 20s/step\n",
      "Epoch 193/350\n",
      "14/14 - 279s - loss: 0.0144 - val_loss: 0.0144 - 279s/epoch - 20s/step\n",
      "Epoch 194/350\n",
      "14/14 - 279s - loss: 0.0144 - val_loss: 0.0144 - 279s/epoch - 20s/step\n",
      "Epoch 195/350\n",
      "14/14 - 283s - loss: 0.0144 - val_loss: 0.0144 - 283s/epoch - 20s/step\n",
      "Epoch 196/350\n",
      "14/14 - 282s - loss: 0.0144 - val_loss: 0.0145 - 282s/epoch - 20s/step\n",
      "Epoch 197/350\n",
      "14/14 - 281s - loss: 0.0143 - val_loss: 0.0144 - 281s/epoch - 20s/step\n",
      "Epoch 198/350\n",
      "14/14 - 281s - loss: 0.0144 - val_loss: 0.0145 - 281s/epoch - 20s/step\n",
      "Epoch 199/350\n",
      "14/14 - 279s - loss: 0.0143 - val_loss: 0.0145 - 279s/epoch - 20s/step\n",
      "Epoch 200/350\n",
      "14/14 - 275s - loss: 0.0144 - val_loss: 0.0144 - 275s/epoch - 20s/step\n",
      "Epoch 201/350\n",
      "14/14 - 284s - loss: 0.0144 - val_loss: 0.0144 - 284s/epoch - 20s/step\n",
      "Epoch 202/350\n",
      "14/14 - 282s - loss: 0.0144 - val_loss: 0.0144 - 282s/epoch - 20s/step\n",
      "Epoch 203/350\n",
      "14/14 - 280s - loss: 0.0144 - val_loss: 0.0145 - 280s/epoch - 20s/step\n",
      "Epoch 204/350\n",
      "14/14 - 283s - loss: 0.0143 - val_loss: 0.0144 - 283s/epoch - 20s/step\n",
      "Epoch 205/350\n",
      "14/14 - 281s - loss: 0.0144 - val_loss: 0.0145 - 281s/epoch - 20s/step\n",
      "Epoch 206/350\n",
      "14/14 - 283s - loss: 0.0143 - val_loss: 0.0144 - 283s/epoch - 20s/step\n",
      "Epoch 207/350\n",
      "14/14 - 280s - loss: 0.0144 - val_loss: 0.0144 - 280s/epoch - 20s/step\n",
      "Epoch 208/350\n",
      "14/14 - 281s - loss: 0.0143 - val_loss: 0.0145 - 281s/epoch - 20s/step\n",
      "Epoch 209/350\n",
      "14/14 - 282s - loss: 0.0143 - val_loss: 0.0145 - 282s/epoch - 20s/step\n",
      "Epoch 210/350\n",
      "14/14 - 282s - loss: 0.0143 - val_loss: 0.0145 - 282s/epoch - 20s/step\n",
      "Epoch 211/350\n",
      "14/14 - 281s - loss: 0.0144 - val_loss: 0.0144 - 281s/epoch - 20s/step\n",
      "Epoch 212/350\n",
      "14/14 - 282s - loss: 0.0143 - val_loss: 0.0144 - 282s/epoch - 20s/step\n",
      "Epoch 213/350\n",
      "14/14 - 281s - loss: 0.0143 - val_loss: 0.0144 - 281s/epoch - 20s/step\n",
      "Epoch 214/350\n",
      "14/14 - 279s - loss: 0.0143 - val_loss: 0.0144 - 279s/epoch - 20s/step\n",
      "Epoch 215/350\n",
      "14/14 - 280s - loss: 0.0144 - val_loss: 0.0145 - 280s/epoch - 20s/step\n",
      "Epoch 216/350\n",
      "14/14 - 275s - loss: 0.0143 - val_loss: 0.0144 - 275s/epoch - 20s/step\n",
      "Epoch 217/350\n",
      "14/14 - 284s - loss: 0.0143 - val_loss: 0.0144 - 284s/epoch - 20s/step\n",
      "Epoch 218/350\n",
      "14/14 - 284s - loss: 0.0143 - val_loss: 0.0144 - 284s/epoch - 20s/step\n",
      "Epoch 219/350\n",
      "14/14 - 289s - loss: 0.0143 - val_loss: 0.0144 - 289s/epoch - 21s/step\n",
      "Epoch 220/350\n",
      "14/14 - 289s - loss: 0.0144 - val_loss: 0.0145 - 289s/epoch - 21s/step\n",
      "Epoch 221/350\n",
      "14/14 - 287s - loss: 0.0144 - val_loss: 0.0144 - 287s/epoch - 20s/step\n",
      "Epoch 222/350\n",
      "14/14 - 288s - loss: 0.0143 - val_loss: 0.0144 - 288s/epoch - 21s/step\n",
      "Epoch 223/350\n",
      "14/14 - 290s - loss: 0.0143 - val_loss: 0.0144 - 290s/epoch - 21s/step\n",
      "Epoch 224/350\n",
      "14/14 - 284s - loss: 0.0143 - val_loss: 0.0144 - 284s/epoch - 20s/step\n",
      "Epoch 225/350\n",
      "14/14 - 290s - loss: 0.0143 - val_loss: 0.0144 - 290s/epoch - 21s/step\n",
      "Epoch 226/350\n",
      "14/14 - 286s - loss: 0.0143 - val_loss: 0.0144 - 286s/epoch - 20s/step\n",
      "Epoch 227/350\n",
      "14/14 - 287s - loss: 0.0144 - val_loss: 0.0144 - 287s/epoch - 20s/step\n",
      "Epoch 228/350\n",
      "14/14 - 288s - loss: 0.0143 - val_loss: 0.0144 - 288s/epoch - 21s/step\n",
      "Epoch 229/350\n",
      "14/14 - 284s - loss: 0.0143 - val_loss: 0.0144 - 284s/epoch - 20s/step\n",
      "Epoch 230/350\n",
      "14/14 - 280s - loss: 0.0143 - val_loss: 0.0144 - 280s/epoch - 20s/step\n",
      "Epoch 231/350\n",
      "14/14 - 282s - loss: 0.0143 - val_loss: 0.0144 - 282s/epoch - 20s/step\n",
      "Epoch 232/350\n",
      "14/14 - 283s - loss: 0.0143 - val_loss: 0.0144 - 283s/epoch - 20s/step\n",
      "Epoch 233/350\n",
      "14/14 - 281s - loss: 0.0143 - val_loss: 0.0144 - 281s/epoch - 20s/step\n",
      "Epoch 234/350\n",
      "14/14 - 278s - loss: 0.0143 - val_loss: 0.0144 - 278s/epoch - 20s/step\n",
      "Epoch 235/350\n",
      "14/14 - 277s - loss: 0.0143 - val_loss: 0.0144 - 277s/epoch - 20s/step\n",
      "Epoch 236/350\n",
      "14/14 - 283s - loss: 0.0143 - val_loss: 0.0144 - 283s/epoch - 20s/step\n",
      "Epoch 237/350\n",
      "14/14 - 281s - loss: 0.0143 - val_loss: 0.0144 - 281s/epoch - 20s/step\n",
      "Epoch 238/350\n",
      "14/14 - 279s - loss: 0.0143 - val_loss: 0.0144 - 279s/epoch - 20s/step\n",
      "Epoch 239/350\n",
      "14/14 - 277s - loss: 0.0143 - val_loss: 0.0144 - 277s/epoch - 20s/step\n",
      "Epoch 240/350\n",
      "14/14 - 281s - loss: 0.0143 - val_loss: 0.0144 - 281s/epoch - 20s/step\n",
      "Epoch 241/350\n",
      "14/14 - 279s - loss: 0.0143 - val_loss: 0.0144 - 279s/epoch - 20s/step\n",
      "Epoch 242/350\n",
      "14/14 - 283s - loss: 0.0143 - val_loss: 0.0144 - 283s/epoch - 20s/step\n",
      "Epoch 243/350\n",
      "14/14 - 284s - loss: 0.0143 - val_loss: 0.0144 - 284s/epoch - 20s/step\n",
      "Epoch 244/350\n",
      "14/14 - 280s - loss: 0.0143 - val_loss: 0.0144 - 280s/epoch - 20s/step\n",
      "Epoch 245/350\n",
      "14/14 - 280s - loss: 0.0143 - val_loss: 0.0144 - 280s/epoch - 20s/step\n",
      "Epoch 246/350\n",
      "14/14 - 281s - loss: 0.0143 - val_loss: 0.0144 - 281s/epoch - 20s/step\n",
      "Epoch 247/350\n",
      "14/14 - 280s - loss: 0.0143 - val_loss: 0.0144 - 280s/epoch - 20s/step\n",
      "Epoch 248/350\n",
      "14/14 - 278s - loss: 0.0143 - val_loss: 0.0144 - 278s/epoch - 20s/step\n",
      "Epoch 249/350\n",
      "14/14 - 280s - loss: 0.0143 - val_loss: 0.0144 - 280s/epoch - 20s/step\n",
      "Epoch 250/350\n",
      "14/14 - 286s - loss: 0.0143 - val_loss: 0.0144 - 286s/epoch - 20s/step\n",
      "Epoch 251/350\n",
      "14/14 - 275s - loss: 0.0143 - val_loss: 0.0144 - 275s/epoch - 20s/step\n",
      "Epoch 252/350\n",
      "14/14 - 285s - loss: 0.0143 - val_loss: 0.0144 - 285s/epoch - 20s/step\n",
      "Epoch 253/350\n",
      "14/14 - 286s - loss: 0.0143 - val_loss: 0.0144 - 286s/epoch - 20s/step\n",
      "Epoch 254/350\n",
      "14/14 - 278s - loss: 0.0143 - val_loss: 0.0144 - 278s/epoch - 20s/step\n",
      "Epoch 255/350\n",
      "14/14 - 286s - loss: 0.0143 - val_loss: 0.0144 - 286s/epoch - 20s/step\n",
      "Epoch 256/350\n",
      "14/14 - 282s - loss: 0.0143 - val_loss: 0.0144 - 282s/epoch - 20s/step\n",
      "Epoch 257/350\n",
      "14/14 - 287s - loss: 0.0143 - val_loss: 0.0144 - 287s/epoch - 20s/step\n",
      "Epoch 258/350\n",
      "14/14 - 280s - loss: 0.0143 - val_loss: 0.0144 - 280s/epoch - 20s/step\n",
      "Epoch 259/350\n",
      "14/14 - 282s - loss: 0.0144 - val_loss: 0.0144 - 282s/epoch - 20s/step\n",
      "Epoch 260/350\n",
      "14/14 - 283s - loss: 0.0143 - val_loss: 0.0143 - 283s/epoch - 20s/step\n",
      "Epoch 261/350\n",
      "14/14 - 276s - loss: 0.0143 - val_loss: 0.0144 - 276s/epoch - 20s/step\n",
      "Epoch 262/350\n",
      "14/14 - 284s - loss: 0.0143 - val_loss: 0.0144 - 284s/epoch - 20s/step\n",
      "Epoch 263/350\n",
      "14/14 - 283s - loss: 0.0143 - val_loss: 0.0143 - 283s/epoch - 20s/step\n",
      "Epoch 264/350\n",
      "14/14 - 285s - loss: 0.0143 - val_loss: 0.0143 - 285s/epoch - 20s/step\n",
      "Epoch 265/350\n",
      "14/14 - 281s - loss: 0.0143 - val_loss: 0.0144 - 281s/epoch - 20s/step\n",
      "Epoch 266/350\n",
      "14/14 - 281s - loss: 0.0142 - val_loss: 0.0144 - 281s/epoch - 20s/step\n",
      "Epoch 267/350\n",
      "14/14 - 283s - loss: 0.0142 - val_loss: 0.0143 - 283s/epoch - 20s/step\n",
      "Epoch 268/350\n",
      "14/14 - 283s - loss: 0.0143 - val_loss: 0.0143 - 283s/epoch - 20s/step\n",
      "Epoch 269/350\n",
      "14/14 - 283s - loss: 0.0142 - val_loss: 0.0143 - 283s/epoch - 20s/step\n",
      "Epoch 270/350\n",
      "14/14 - 283s - loss: 0.0142 - val_loss: 0.0143 - 283s/epoch - 20s/step\n",
      "Epoch 271/350\n",
      "14/14 - 283s - loss: 0.0142 - val_loss: 0.0143 - 283s/epoch - 20s/step\n",
      "Epoch 272/350\n",
      "14/14 - 282s - loss: 0.0142 - val_loss: 0.0143 - 282s/epoch - 20s/step\n",
      "Epoch 273/350\n",
      "14/14 - 286s - loss: 0.0142 - val_loss: 0.0143 - 286s/epoch - 20s/step\n",
      "Epoch 274/350\n",
      "14/14 - 280s - loss: 0.0142 - val_loss: 0.0143 - 280s/epoch - 20s/step\n",
      "Epoch 275/350\n",
      "14/14 - 277s - loss: 0.0142 - val_loss: 0.0143 - 277s/epoch - 20s/step\n",
      "Epoch 276/350\n",
      "14/14 - 288s - loss: 0.0142 - val_loss: 0.0143 - 288s/epoch - 21s/step\n",
      "Epoch 277/350\n",
      "14/14 - 279s - loss: 0.0142 - val_loss: 0.0143 - 279s/epoch - 20s/step\n",
      "Epoch 278/350\n",
      "14/14 - 286s - loss: 0.0142 - val_loss: 0.0143 - 286s/epoch - 20s/step\n",
      "Epoch 279/350\n",
      "14/14 - 282s - loss: 0.0142 - val_loss: 0.0143 - 282s/epoch - 20s/step\n",
      "Epoch 280/350\n",
      "14/14 - 286s - loss: 0.0141 - val_loss: 0.0143 - 286s/epoch - 20s/step\n",
      "Epoch 281/350\n",
      "14/14 - 286s - loss: 0.0142 - val_loss: 0.0143 - 286s/epoch - 20s/step\n",
      "Epoch 282/350\n",
      "14/14 - 293s - loss: 0.0142 - val_loss: 0.0143 - 293s/epoch - 21s/step\n",
      "Epoch 283/350\n",
      "14/14 - 294s - loss: 0.0142 - val_loss: 0.0143 - 294s/epoch - 21s/step\n",
      "Epoch 284/350\n",
      "14/14 - 293s - loss: 0.0141 - val_loss: 0.0143 - 293s/epoch - 21s/step\n",
      "Epoch 285/350\n",
      "14/14 - 288s - loss: 0.0141 - val_loss: 0.0142 - 288s/epoch - 21s/step\n",
      "Epoch 286/350\n",
      "14/14 - 291s - loss: 0.0142 - val_loss: 0.0143 - 291s/epoch - 21s/step\n",
      "Epoch 287/350\n",
      "14/14 - 289s - loss: 0.0141 - val_loss: 0.0142 - 289s/epoch - 21s/step\n",
      "Epoch 288/350\n",
      "14/14 - 283s - loss: 0.0141 - val_loss: 0.0142 - 283s/epoch - 20s/step\n",
      "Epoch 289/350\n",
      "14/14 - 289s - loss: 0.0141 - val_loss: 0.0142 - 289s/epoch - 21s/step\n",
      "Epoch 290/350\n",
      "14/14 - 291s - loss: 0.0141 - val_loss: 0.0143 - 291s/epoch - 21s/step\n",
      "Epoch 291/350\n",
      "14/14 - 287s - loss: 0.0141 - val_loss: 0.0142 - 287s/epoch - 20s/step\n",
      "Epoch 292/350\n",
      "14/14 - 291s - loss: 0.0141 - val_loss: 0.0142 - 291s/epoch - 21s/step\n",
      "Epoch 293/350\n",
      "14/14 - 286s - loss: 0.0141 - val_loss: 0.0143 - 286s/epoch - 20s/step\n",
      "Epoch 294/350\n",
      "14/14 - 288s - loss: 0.0141 - val_loss: 0.0142 - 288s/epoch - 21s/step\n",
      "Epoch 295/350\n",
      "14/14 - 289s - loss: 0.0141 - val_loss: 0.0143 - 289s/epoch - 21s/step\n",
      "Epoch 296/350\n",
      "14/14 - 288s - loss: 0.0141 - val_loss: 0.0142 - 288s/epoch - 21s/step\n",
      "Epoch 297/350\n",
      "14/14 - 281s - loss: 0.0141 - val_loss: 0.0142 - 281s/epoch - 20s/step\n",
      "Epoch 298/350\n",
      "14/14 - 282s - loss: 0.0141 - val_loss: 0.0142 - 282s/epoch - 20s/step\n",
      "Epoch 299/350\n",
      "14/14 - 276s - loss: 0.0141 - val_loss: 0.0142 - 276s/epoch - 20s/step\n",
      "Epoch 300/350\n",
      "14/14 - 280s - loss: 0.0141 - val_loss: 0.0143 - 280s/epoch - 20s/step\n",
      "Epoch 301/350\n",
      "14/14 - 287s - loss: 0.0141 - val_loss: 0.0142 - 287s/epoch - 21s/step\n",
      "Epoch 302/350\n",
      "14/14 - 284s - loss: 0.0141 - val_loss: 0.0142 - 284s/epoch - 20s/step\n",
      "Epoch 303/350\n",
      "14/14 - 283s - loss: 0.0141 - val_loss: 0.0142 - 283s/epoch - 20s/step\n",
      "Epoch 304/350\n",
      "14/14 - 278s - loss: 0.0141 - val_loss: 0.0142 - 278s/epoch - 20s/step\n",
      "Epoch 305/350\n",
      "14/14 - 275s - loss: 0.0141 - val_loss: 0.0142 - 275s/epoch - 20s/step\n",
      "Epoch 306/350\n",
      "14/14 - 285s - loss: 0.0141 - val_loss: 0.0142 - 285s/epoch - 20s/step\n",
      "Epoch 307/350\n",
      "14/14 - 281s - loss: 0.0141 - val_loss: 0.0142 - 281s/epoch - 20s/step\n",
      "Epoch 308/350\n",
      "14/14 - 285s - loss: 0.0141 - val_loss: 0.0142 - 285s/epoch - 20s/step\n",
      "Epoch 309/350\n",
      "14/14 - 280s - loss: 0.0141 - val_loss: 0.0143 - 280s/epoch - 20s/step\n",
      "Epoch 310/350\n",
      "14/14 - 286s - loss: 0.0141 - val_loss: 0.0142 - 286s/epoch - 20s/step\n",
      "Epoch 311/350\n",
      "14/14 - 283s - loss: 0.0141 - val_loss: 0.0142 - 283s/epoch - 20s/step\n",
      "Epoch 312/350\n",
      "14/14 - 285s - loss: 0.0141 - val_loss: 0.0142 - 285s/epoch - 20s/step\n",
      "Epoch 313/350\n",
      "14/14 - 283s - loss: 0.0141 - val_loss: 0.0142 - 283s/epoch - 20s/step\n",
      "Epoch 314/350\n",
      "14/14 - 279s - loss: 0.0141 - val_loss: 0.0142 - 279s/epoch - 20s/step\n",
      "Epoch 315/350\n",
      "14/14 - 281s - loss: 0.0141 - val_loss: 0.0143 - 281s/epoch - 20s/step\n",
      "Epoch 316/350\n",
      "14/14 - 285s - loss: 0.0141 - val_loss: 0.0142 - 285s/epoch - 20s/step\n",
      "Epoch 317/350\n",
      "14/14 - 283s - loss: 0.0141 - val_loss: 0.0142 - 283s/epoch - 20s/step\n",
      "Epoch 318/350\n",
      "14/14 - 283s - loss: 0.0141 - val_loss: 0.0142 - 283s/epoch - 20s/step\n",
      "Epoch 319/350\n",
      "14/14 - 282s - loss: 0.0140 - val_loss: 0.0142 - 282s/epoch - 20s/step\n",
      "Epoch 320/350\n",
      "14/14 - 284s - loss: 0.0141 - val_loss: 0.0142 - 284s/epoch - 20s/step\n",
      "Epoch 321/350\n",
      "14/14 - 280s - loss: 0.0140 - val_loss: 0.0142 - 280s/epoch - 20s/step\n",
      "Epoch 322/350\n",
      "14/14 - 281s - loss: 0.0140 - val_loss: 0.0142 - 281s/epoch - 20s/step\n",
      "Epoch 323/350\n",
      "14/14 - 279s - loss: 0.0141 - val_loss: 0.0142 - 279s/epoch - 20s/step\n",
      "Epoch 324/350\n",
      "14/14 - 281s - loss: 0.0140 - val_loss: 0.0142 - 281s/epoch - 20s/step\n",
      "Epoch 325/350\n",
      "14/14 - 288s - loss: 0.0141 - val_loss: 0.0142 - 288s/epoch - 21s/step\n",
      "Epoch 326/350\n",
      "14/14 - 280s - loss: 0.0140 - val_loss: 0.0142 - 280s/epoch - 20s/step\n",
      "Epoch 327/350\n",
      "14/14 - 281s - loss: 0.0141 - val_loss: 0.0142 - 281s/epoch - 20s/step\n",
      "Epoch 328/350\n",
      "14/14 - 286s - loss: 0.0140 - val_loss: 0.0142 - 286s/epoch - 20s/step\n",
      "Epoch 329/350\n",
      "14/14 - 278s - loss: 0.0140 - val_loss: 0.0142 - 278s/epoch - 20s/step\n",
      "Epoch 330/350\n",
      "14/14 - 283s - loss: 0.0140 - val_loss: 0.0142 - 283s/epoch - 20s/step\n",
      "Epoch 331/350\n",
      "14/14 - 277s - loss: 0.0140 - val_loss: 0.0142 - 277s/epoch - 20s/step\n",
      "Epoch 332/350\n",
      "14/14 - 282s - loss: 0.0140 - val_loss: 0.0142 - 282s/epoch - 20s/step\n",
      "Epoch 333/350\n",
      "14/14 - 279s - loss: 0.0140 - val_loss: 0.0142 - 279s/epoch - 20s/step\n",
      "Epoch 334/350\n",
      "14/14 - 277s - loss: 0.0140 - val_loss: 0.0142 - 277s/epoch - 20s/step\n",
      "Epoch 335/350\n",
      "14/14 - 283s - loss: 0.0140 - val_loss: 0.0142 - 283s/epoch - 20s/step\n",
      "Epoch 336/350\n",
      "14/14 - 278s - loss: 0.0140 - val_loss: 0.0142 - 278s/epoch - 20s/step\n",
      "Epoch 337/350\n",
      "14/14 - 279s - loss: 0.0140 - val_loss: 0.0142 - 279s/epoch - 20s/step\n",
      "Epoch 338/350\n",
      "14/14 - 280s - loss: 0.0140 - val_loss: 0.0142 - 280s/epoch - 20s/step\n",
      "Epoch 339/350\n",
      "14/14 - 285s - loss: 0.0140 - val_loss: 0.0142 - 285s/epoch - 20s/step\n",
      "Epoch 340/350\n",
      "14/14 - 277s - loss: 0.0140 - val_loss: 0.0142 - 277s/epoch - 20s/step\n",
      "Epoch 341/350\n",
      "14/14 - 282s - loss: 0.0140 - val_loss: 0.0142 - 282s/epoch - 20s/step\n",
      "Epoch 342/350\n",
      "14/14 - 289s - loss: 0.0140 - val_loss: 0.0142 - 289s/epoch - 21s/step\n",
      "Epoch 343/350\n",
      "14/14 - 287s - loss: 0.0140 - val_loss: 0.0141 - 287s/epoch - 21s/step\n",
      "Epoch 344/350\n",
      "14/14 - 286s - loss: 0.0140 - val_loss: 0.0142 - 286s/epoch - 20s/step\n",
      "Epoch 345/350\n",
      "14/14 - 288s - loss: 0.0140 - val_loss: 0.0142 - 288s/epoch - 21s/step\n",
      "Epoch 346/350\n",
      "14/14 - 287s - loss: 0.0140 - val_loss: 0.0142 - 287s/epoch - 20s/step\n",
      "Epoch 347/350\n",
      "14/14 - 285s - loss: 0.0140 - val_loss: 0.0142 - 285s/epoch - 20s/step\n",
      "Epoch 348/350\n",
      "14/14 - 285s - loss: 0.0140 - val_loss: 0.0141 - 285s/epoch - 20s/step\n",
      "Epoch 349/350\n",
      "14/14 - 292s - loss: 0.0140 - val_loss: 0.0142 - 292s/epoch - 21s/step\n",
      "Epoch 350/350\n",
      "14/14 - 303s - loss: 0.0140 - val_loss: 0.0142 - 303s/epoch - 22s/step\n"
     ]
    }
   ],
   "source": [
    "ann_fit_hist = autoencoder.fit(df_data_only_inverted, df_data_only_inverted,\n",
    "                                       epochs=n_epoch,\n",
    "                                       callbacks=[checkpoint],\n",
    "                                       shuffle=True,\n",
    "                                       batch_size=40000,\n",
    "                                       validation_split=0.10,\n",
    "                                       verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_combined = np.vstack((ann_fit_hist.history['loss'], ann_fit_hist.history['val_loss'])).T\n",
    "np.savetxt('ann_network_loss.txt', loss_combined)\n",
    "i_best = np.argmin(ann_fit_hist.history['val_loss'])\n",
    "plt.plot(ann_fit_hist.history['loss'], label='Train')\n",
    "plt.plot(ann_fit_hist.history['val_loss'], label='Validation')\n",
    "plt.axvline(np.arange(n_epoch)[i_best], ls='--', color='black', alpha=0.5)\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss value')\n",
    "plt.ylim(np.nanmin(loss_combined)*0.95, np.nanpercentile(loss_combined, 99))\n",
    "plt.xlim(-1, n_epoch)\n",
    "plt.grid(ls='--', alpha=0.2, color='black')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('ann_network_loss.png', dpi=250)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from glob import glob\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras import backend as K\n",
    "#from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ann_fit_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(h5_weight_files) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m----------------------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRestoring epoch \u001b[39m\u001b[38;5;132;01m{:.0f}\u001b[39;00m\u001b[38;5;124m with the loss (\u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i_best, \u001b[43mann_fit_hist\u001b[49m\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m][i_best\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m     10\u001b[0m     autoencoder\u001b[38;5;241m.\u001b[39mload_weights(h5_weight_files[\u001b[38;5;241m0\u001b[39m], by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m     sub_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch_\u001b[39m\u001b[38;5;132;01m{:03.0f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i_best)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ann_fit_hist' is not defined"
     ]
    }
   ],
   "source": [
    "print('')\n",
    "        # recover weights of the selected model and compute predictions\n",
    "for i_best in [10, 25, 50, 100, 150, 200, 250, 300]:\n",
    "\n",
    "    h5_weight_files = glob('/data/praveen/autoencoder-runs/'+'ann_model_run_{:03.0f}-*-*.h5'.format(i_best))\n",
    "\n",
    "    if len(h5_weight_files) == 1:\n",
    "        print('----------------------------------------------------------------')\n",
    "        print('Restoring epoch {:.0f} with the loss ({:.4f}).'.format(i_best, ann_fit_hist.history['val_loss'][i_best-1]))\n",
    "        autoencoder.load_weights(h5_weight_files[0], by_name=True)\n",
    "\n",
    "        sub_dir = 'epoch_{:03.0f}'.format(i_best)\n",
    "        os.system('mkdir ' + sub_dir)\n",
    "        os.chdir(sub_dir)\n",
    "\n",
    "        print('Saving selected model weights')\n",
    "        autoencoder.save_weights(out_model_file)\n",
    "\n",
    "        #print('Predicting values')\n",
    "        #processed_data_all = autoencoder.predict(df_data_only_inverted, verbose=2, batch_size=20)\n",
    "\n",
    "        #plot_sample_spectra()\n",
    "\n",
    "        #print('')\n",
    "        #os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3aa1867c408c14afe351cfd5d1be181646832c7964023d6477fd09a3c85411b7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
